{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CMSC 478 Machine Learning\n",
    "\n",
    "\n",
    "## Getting Started with Tensorflow, Keras, and Tensorboard\n",
    "\n",
    "### Instructor: Fereydoon Vafaei"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Benjamin Thai MX08618"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook helps you get started with Tensorflow/Keras API. **READ ALL SECTIONS VERY CAREFULLY!**\n",
    "\n",
    "**Note**: You should install Tensorflow 2 before starting this notebook.<br> If you have not installed Tensorflow 2 or have installed previous versions of Tensorflow, you need to [install Tensorflow 2](https://www.tensorflow.org/install) before proceeding. Alternatively, you can install Tensorflow 2 using [conda environment](https://docs.anaconda.com/anaconda/user-guide/tasks/tensorflow/). CPU-only TensorFlow is sufficient for this course."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RUN ALL CELLS REQUIREMENT**: You must run all cells to get the outputs and then attempt exercises. Otherwise, if any cell is not run with the correct output, your notebook gets ZERO.\n",
    "\n",
    "<b>Course Policy Reminder:</b>\n",
    "Debugging and error resolution are always students' responsbility. This policy will be enforced in email communications and the office hours. Keep in mind that all assignments are individual graded tasks. Any collaboration with other students is strictly prohibited and is considered as cheating. Students should NOT share any answer, solution, or code with other students. Violations of these policies would be penalized according to UMBC academic integrity policy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents:\n",
    "* [Installation Verification](#Installation-Verification)\n",
    "* [A Simple Regression NN](#A-One-Layer-One-Neuron-Regression-Neural-Network-using-Tensorflow/Keras)\n",
    "* [A Multi-layer NN on MNIST Dataset](#A-Multi-Layer-NN-for-Multi-Class-Classification-on-MNIST-Dataset)\n",
    "* [Eager Execution in Tensorflow-2](#Eager-Execution-in-Tensorflow-2)\n",
    "* [Creating the model using the Sequential API](#Creating-the-model-using-the-Sequential-API)\n",
    "* [Fashion MNIST Dataset](#Fashion-MNIST-Dataset)\n",
    "* [California House Pricing](#California-House-Pricing)\n",
    "* [Saving and Restoring the Models](#Saving-and-Restoring-the-Models)\n",
    "* [Callbacks](#Callbacks)\n",
    "* [Tensorboard](#Tensorboard)\n",
    "* [Exercise-1](#Exercise-1)\n",
    "* [Exercise-2](#Exercise-2)\n",
    "* [References](#References)\n",
    "* [Grading and Submission](#Grading-and-Submission)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensorflow is one of the most popular ML/DL frameworks. Watch this video first:\n",
    "\n",
    "https://www.youtube.com/watch?v=744f60NyAgc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installation Verification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verify your installation using the following cells.\n",
    "\n",
    "**Note**: It is recommended that you install (or upgrade to) the latest stable version of tensorflow 2. While the minimum requirement for tf version for this notebook is 2.0.0 (which is needed to run the textbook and slides codes), it is your responsibility to update tf to the latest stable version for the assignments when/if needed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.8.0'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your tf/keras version should be 2.x.x (latest stable version is recommended)\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.8.0'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Also check that all important packages can be imported. \n",
    "# Note: If you use a separate conda environment for tf, you may need to reinstall some of these libraries.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A One-Layer One-Neuron Regression Neural Network using Tensorflow/Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our first example is a regression NN with only one layer and one neuron to recognize the pattern of a sequence of numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "1/1 [==============================] - 0s 434ms/step - loss: 2.1289\n",
      "Epoch 2/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.8205\n",
      "Epoch 3/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 1.5748\n",
      "Epoch 4/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 1.3787\n",
      "Epoch 5/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 1.2215\n",
      "Epoch 6/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 1.0950\n",
      "Epoch 7/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.9927\n",
      "Epoch 8/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.9095\n",
      "Epoch 9/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.8415\n",
      "Epoch 10/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.7853\n",
      "Epoch 11/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7386\n",
      "Epoch 12/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6994\n",
      "Epoch 13/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.6661\n",
      "Epoch 14/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6376\n",
      "Epoch 15/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.6128\n",
      "Epoch 16/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5910\n",
      "Epoch 17/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.5716\n",
      "Epoch 18/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5541\n",
      "Epoch 19/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.5383\n",
      "Epoch 20/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.5237\n",
      "Epoch 21/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.5101\n",
      "Epoch 22/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4975\n",
      "Epoch 23/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4855\n",
      "Epoch 24/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4742\n",
      "Epoch 25/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4634\n",
      "Epoch 26/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.4530\n",
      "Epoch 27/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4431\n",
      "Epoch 28/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.4335\n",
      "Epoch 29/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4242\n",
      "Epoch 30/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4151\n",
      "Epoch 31/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.4063\n",
      "Epoch 32/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.3978\n",
      "Epoch 33/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.3895\n",
      "Epoch 34/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.3813\n",
      "Epoch 35/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.3734\n",
      "Epoch 36/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3657\n",
      "Epoch 37/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.3581\n",
      "Epoch 38/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.3507\n",
      "Epoch 39/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.3435\n",
      "Epoch 40/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.3364\n",
      "Epoch 41/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.3294\n",
      "Epoch 42/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.3227\n",
      "Epoch 43/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.3160\n",
      "Epoch 44/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.3095\n",
      "Epoch 45/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.3031\n",
      "Epoch 46/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.2969\n",
      "Epoch 47/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.2908\n",
      "Epoch 48/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.2848\n",
      "Epoch 49/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.2790\n",
      "Epoch 50/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.2732\n",
      "Epoch 51/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.2676\n",
      "Epoch 52/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.2621\n",
      "Epoch 53/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.2567\n",
      "Epoch 54/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.2515\n",
      "Epoch 55/1000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.2463\n",
      "Epoch 56/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.2412\n",
      "Epoch 57/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.2363\n",
      "Epoch 58/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.2314\n",
      "Epoch 59/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.2267\n",
      "Epoch 60/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.2220\n",
      "Epoch 61/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.2175\n",
      "Epoch 62/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.2130\n",
      "Epoch 63/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.2086\n",
      "Epoch 64/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.2043\n",
      "Epoch 65/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.2001\n",
      "Epoch 66/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1960\n",
      "Epoch 67/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1920\n",
      "Epoch 68/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.1881\n",
      "Epoch 69/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.1842\n",
      "Epoch 70/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1804\n",
      "Epoch 71/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1767\n",
      "Epoch 72/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1731\n",
      "Epoch 73/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1695\n",
      "Epoch 74/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1660\n",
      "Epoch 75/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1626\n",
      "Epoch 76/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1593\n",
      "Epoch 77/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1560\n",
      "Epoch 78/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1528\n",
      "Epoch 79/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1497\n",
      "Epoch 80/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1466\n",
      "Epoch 81/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1436\n",
      "Epoch 82/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1406\n",
      "Epoch 83/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1377\n",
      "Epoch 84/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1349\n",
      "Epoch 85/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1321\n",
      "Epoch 86/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1294\n",
      "Epoch 87/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1268\n",
      "Epoch 88/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1242\n",
      "Epoch 89/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1216\n",
      "Epoch 90/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1191\n",
      "Epoch 91/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1167\n",
      "Epoch 92/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1143\n",
      "Epoch 93/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1119\n",
      "Epoch 94/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1096\n",
      "Epoch 95/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1074\n",
      "Epoch 96/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1052\n",
      "Epoch 97/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1030\n",
      "Epoch 98/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1009\n",
      "Epoch 99/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0988\n",
      "Epoch 100/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0968\n",
      "Epoch 101/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0948\n",
      "Epoch 102/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0929\n",
      "Epoch 103/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0910\n",
      "Epoch 104/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0891\n",
      "Epoch 105/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0873\n",
      "Epoch 106/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0855\n",
      "Epoch 107/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0837\n",
      "Epoch 108/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0820\n",
      "Epoch 109/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0803\n",
      "Epoch 110/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0787\n",
      "Epoch 111/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0770\n",
      "Epoch 112/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0755\n",
      "Epoch 113/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0739\n",
      "Epoch 114/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0724\n",
      "Epoch 115/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0709\n",
      "Epoch 116/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0694\n",
      "Epoch 117/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0680\n",
      "Epoch 118/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0666\n",
      "Epoch 119/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0653\n",
      "Epoch 120/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0639\n",
      "Epoch 121/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0626\n",
      "Epoch 122/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0613\n",
      "Epoch 123/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0601\n",
      "Epoch 124/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0588\n",
      "Epoch 125/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0576\n",
      "Epoch 126/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0564\n",
      "Epoch 127/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0553\n",
      "Epoch 128/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0541\n",
      "Epoch 129/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0530\n",
      "Epoch 130/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0519\n",
      "Epoch 131/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0509\n",
      "Epoch 132/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0498\n",
      "Epoch 133/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0488\n",
      "Epoch 134/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0478\n",
      "Epoch 135/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0468\n",
      "Epoch 136/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0459\n",
      "Epoch 137/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0449\n",
      "Epoch 138/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0440\n",
      "Epoch 139/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0431\n",
      "Epoch 140/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0422\n",
      "Epoch 141/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0413\n",
      "Epoch 142/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0405\n",
      "Epoch 143/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0397\n",
      "Epoch 144/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0388\n",
      "Epoch 145/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0380\n",
      "Epoch 146/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0373\n",
      "Epoch 147/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0365\n",
      "Epoch 148/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0357\n",
      "Epoch 149/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0350\n",
      "Epoch 150/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0343\n",
      "Epoch 151/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0336\n",
      "Epoch 152/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0329\n",
      "Epoch 153/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0322\n",
      "Epoch 154/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0316\n",
      "Epoch 155/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0309\n",
      "Epoch 156/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0303\n",
      "Epoch 157/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0297\n",
      "Epoch 158/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0290\n",
      "Epoch 159/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0284\n",
      "Epoch 160/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0279\n",
      "Epoch 161/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0273\n",
      "Epoch 162/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0267\n",
      "Epoch 163/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0262\n",
      "Epoch 164/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0256\n",
      "Epoch 165/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0251\n",
      "Epoch 166/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0246\n",
      "Epoch 167/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0241\n",
      "Epoch 168/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0236\n",
      "Epoch 169/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0231\n",
      "Epoch 170/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0226\n",
      "Epoch 171/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0222\n",
      "Epoch 172/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0217\n",
      "Epoch 173/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0213\n",
      "Epoch 174/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0208\n",
      "Epoch 175/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0204\n",
      "Epoch 176/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0200\n",
      "Epoch 177/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0196\n",
      "Epoch 178/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0192\n",
      "Epoch 179/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0188\n",
      "Epoch 180/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0184\n",
      "Epoch 181/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0180\n",
      "Epoch 182/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0176\n",
      "Epoch 183/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0173\n",
      "Epoch 184/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0169\n",
      "Epoch 185/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0166\n",
      "Epoch 186/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0162\n",
      "Epoch 187/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0159\n",
      "Epoch 188/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0156\n",
      "Epoch 189/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0153\n",
      "Epoch 190/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0149\n",
      "Epoch 191/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0146\n",
      "Epoch 192/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0143\n",
      "Epoch 193/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0140\n",
      "Epoch 194/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0138\n",
      "Epoch 195/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0135\n",
      "Epoch 196/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0132\n",
      "Epoch 197/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0129\n",
      "Epoch 198/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0127\n",
      "Epoch 199/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0124\n",
      "Epoch 200/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0121\n",
      "Epoch 201/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0119\n",
      "Epoch 202/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0117\n",
      "Epoch 203/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0114\n",
      "Epoch 204/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0112\n",
      "Epoch 205/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0110\n",
      "Epoch 206/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0107\n",
      "Epoch 207/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0105\n",
      "Epoch 208/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0103\n",
      "Epoch 209/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0101\n",
      "Epoch 210/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0099\n",
      "Epoch 211/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0097\n",
      "Epoch 212/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0095\n",
      "Epoch 213/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0093\n",
      "Epoch 214/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0091\n",
      "Epoch 215/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0089\n",
      "Epoch 216/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0087\n",
      "Epoch 217/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0085\n",
      "Epoch 218/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0084\n",
      "Epoch 219/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0082\n",
      "Epoch 220/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0080\n",
      "Epoch 221/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0079\n",
      "Epoch 222/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0077\n",
      "Epoch 223/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0075\n",
      "Epoch 224/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0074\n",
      "Epoch 225/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0072\n",
      "Epoch 226/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0071\n",
      "Epoch 227/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0069\n",
      "Epoch 228/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0068\n",
      "Epoch 229/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0067\n",
      "Epoch 230/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0065\n",
      "Epoch 231/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0064\n",
      "Epoch 232/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0063\n",
      "Epoch 233/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0061\n",
      "Epoch 234/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0060\n",
      "Epoch 235/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0059\n",
      "Epoch 236/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0058\n",
      "Epoch 237/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0056\n",
      "Epoch 238/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0055\n",
      "Epoch 239/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0054\n",
      "Epoch 240/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0053\n",
      "Epoch 241/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0052\n",
      "Epoch 242/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0051\n",
      "Epoch 243/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0050\n",
      "Epoch 244/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0049\n",
      "Epoch 245/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0048\n",
      "Epoch 246/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0047\n",
      "Epoch 247/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0046\n",
      "Epoch 248/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0045\n",
      "Epoch 249/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0044\n",
      "Epoch 250/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0043\n",
      "Epoch 251/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0042\n",
      "Epoch 252/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0041\n",
      "Epoch 253/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0040\n",
      "Epoch 254/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0040\n",
      "Epoch 255/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0039\n",
      "Epoch 256/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0038\n",
      "Epoch 257/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0037\n",
      "Epoch 258/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0036\n",
      "Epoch 259/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0036\n",
      "Epoch 260/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0035\n",
      "Epoch 261/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0034\n",
      "Epoch 262/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0034\n",
      "Epoch 263/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0033\n",
      "Epoch 264/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0032\n",
      "Epoch 265/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0032\n",
      "Epoch 266/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0031\n",
      "Epoch 267/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0030\n",
      "Epoch 268/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0030\n",
      "Epoch 269/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0029\n",
      "Epoch 270/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0028\n",
      "Epoch 271/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0028\n",
      "Epoch 272/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0027\n",
      "Epoch 273/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0027\n",
      "Epoch 274/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0026\n",
      "Epoch 275/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0026\n",
      "Epoch 276/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0025\n",
      "Epoch 277/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0025\n",
      "Epoch 278/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0024\n",
      "Epoch 279/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0024\n",
      "Epoch 280/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0023\n",
      "Epoch 281/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0023\n",
      "Epoch 282/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0022\n",
      "Epoch 283/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0022\n",
      "Epoch 284/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0021\n",
      "Epoch 285/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0021\n",
      "Epoch 286/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0020\n",
      "Epoch 287/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0020\n",
      "Epoch 288/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0020\n",
      "Epoch 289/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0019\n",
      "Epoch 290/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0019\n",
      "Epoch 291/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0018\n",
      "Epoch 292/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0018\n",
      "Epoch 293/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0018\n",
      "Epoch 294/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0017\n",
      "Epoch 295/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0017\n",
      "Epoch 296/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0017\n",
      "Epoch 297/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0016\n",
      "Epoch 298/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0016\n",
      "Epoch 299/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0016\n",
      "Epoch 300/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0015\n",
      "Epoch 301/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0015\n",
      "Epoch 302/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0015\n",
      "Epoch 303/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0014\n",
      "Epoch 304/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0014\n",
      "Epoch 305/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0014\n",
      "Epoch 306/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0013\n",
      "Epoch 307/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0013\n",
      "Epoch 308/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0013\n",
      "Epoch 309/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0013\n",
      "Epoch 310/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0012\n",
      "Epoch 311/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0012\n",
      "Epoch 312/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0012\n",
      "Epoch 313/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0012\n",
      "Epoch 314/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0011\n",
      "Epoch 315/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0011\n",
      "Epoch 316/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0011\n",
      "Epoch 317/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0011\n",
      "Epoch 318/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0010\n",
      "Epoch 319/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0010\n",
      "Epoch 320/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0010\n",
      "Epoch 321/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 9.8594e-04\n",
      "Epoch 322/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 9.6569e-04\n",
      "Epoch 323/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 9.4586e-04\n",
      "Epoch 324/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 9.2643e-04\n",
      "Epoch 325/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 9.0740e-04\n",
      "Epoch 326/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 8.8876e-04\n",
      "Epoch 327/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 8.7050e-04\n",
      "Epoch 328/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 8.5262e-04\n",
      "Epoch 329/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 8.3511e-04\n",
      "Epoch 330/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 8.1796e-04\n",
      "Epoch 331/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 8.0116e-04\n",
      "Epoch 332/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 7.8470e-04\n",
      "Epoch 333/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 7.6859e-04\n",
      "Epoch 334/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 7.5279e-04\n",
      "Epoch 335/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 7.3733e-04\n",
      "Epoch 336/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 7.2219e-04\n",
      "Epoch 337/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 7.0735e-04\n",
      "Epoch 338/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 6.9282e-04\n",
      "Epoch 339/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 6.7859e-04\n",
      "Epoch 340/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 6.6465e-04\n",
      "Epoch 341/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 6.5100e-04\n",
      "Epoch 342/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 6.3763e-04\n",
      "Epoch 343/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 6.2453e-04\n",
      "Epoch 344/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 6.1171e-04\n",
      "Epoch 345/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 5.9914e-04\n",
      "Epoch 346/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 5.8683e-04\n",
      "Epoch 347/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 5.7478e-04\n",
      "Epoch 348/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 5.6297e-04\n",
      "Epoch 349/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 5.5141e-04\n",
      "Epoch 350/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 5.4008e-04\n",
      "Epoch 351/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 5.2899e-04\n",
      "Epoch 352/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 5.1812e-04\n",
      "Epoch 353/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 5.0748e-04\n",
      "Epoch 354/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 4.9706e-04\n",
      "Epoch 355/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 4.8684e-04\n",
      "Epoch 356/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 4.7685e-04\n",
      "Epoch 357/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 4.6705e-04\n",
      "Epoch 358/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 4.5746e-04\n",
      "Epoch 359/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 4.4806e-04\n",
      "Epoch 360/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 4.3886e-04\n",
      "Epoch 361/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 4.2985e-04\n",
      "Epoch 362/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 4.2102e-04\n",
      "Epoch 363/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 4.1237e-04\n",
      "Epoch 364/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 4.0390e-04\n",
      "Epoch 365/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.9560e-04\n",
      "Epoch 366/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.8748e-04\n",
      "Epoch 367/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.7952e-04\n",
      "Epoch 368/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.7172e-04\n",
      "Epoch 369/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.6409e-04\n",
      "Epoch 370/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.5661e-04\n",
      "Epoch 371/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.4928e-04\n",
      "Epoch 372/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.4211e-04\n",
      "Epoch 373/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.3508e-04\n",
      "Epoch 374/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.2820e-04\n",
      "Epoch 375/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.2146e-04\n",
      "Epoch 376/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.1485e-04\n",
      "Epoch 377/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.0838e-04\n",
      "Epoch 378/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.0205e-04\n",
      "Epoch 379/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.9585e-04\n",
      "Epoch 380/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 2.8977e-04\n",
      "Epoch 381/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.8382e-04\n",
      "Epoch 382/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.7799e-04\n",
      "Epoch 383/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.7228e-04\n",
      "Epoch 384/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 2.6669e-04\n",
      "Epoch 385/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.6121e-04\n",
      "Epoch 386/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.5584e-04\n",
      "Epoch 387/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.5059e-04\n",
      "Epoch 388/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 2.4544e-04\n",
      "Epoch 389/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.4040e-04\n",
      "Epoch 390/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.3546e-04\n",
      "Epoch 391/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.3062e-04\n",
      "Epoch 392/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 2.2589e-04\n",
      "Epoch 393/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.2125e-04\n",
      "Epoch 394/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.1670e-04\n",
      "Epoch 395/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.1225e-04\n",
      "Epoch 396/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.0789e-04\n",
      "Epoch 397/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.0362e-04\n",
      "Epoch 398/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.9944e-04\n",
      "Epoch 399/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.9534e-04\n",
      "Epoch 400/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.9133e-04\n",
      "Epoch 401/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.8740e-04\n",
      "Epoch 402/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.8355e-04\n",
      "Epoch 403/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.7978e-04\n",
      "Epoch 404/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.7609e-04\n",
      "Epoch 405/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.7247e-04\n",
      "Epoch 406/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.6893e-04\n",
      "Epoch 407/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.6546e-04\n",
      "Epoch 408/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.6206e-04\n",
      "Epoch 409/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.5873e-04\n",
      "Epoch 410/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.5547e-04\n",
      "Epoch 411/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.5228e-04\n",
      "Epoch 412/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.4915e-04\n",
      "Epoch 413/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.4608e-04\n",
      "Epoch 414/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.4309e-04\n",
      "Epoch 415/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.4015e-04\n",
      "Epoch 416/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.3727e-04\n",
      "Epoch 417/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.3445e-04\n",
      "Epoch 418/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.3169e-04\n",
      "Epoch 419/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.2898e-04\n",
      "Epoch 420/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.2633e-04\n",
      "Epoch 421/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.2374e-04\n",
      "Epoch 422/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.2119e-04\n",
      "Epoch 423/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1871e-04\n",
      "Epoch 424/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.1627e-04\n",
      "Epoch 425/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.1388e-04\n",
      "Epoch 426/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.1154e-04\n",
      "Epoch 427/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.0925e-04\n",
      "Epoch 428/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.0700e-04\n",
      "Epoch 429/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.0481e-04\n",
      "Epoch 430/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.0265e-04\n",
      "Epoch 431/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.0054e-04\n",
      "Epoch 432/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 9.8479e-05\n",
      "Epoch 433/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 9.6457e-05\n",
      "Epoch 434/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 9.4476e-05\n",
      "Epoch 435/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 9.2534e-05\n",
      "Epoch 436/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 9.0635e-05\n",
      "Epoch 437/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 8.8773e-05\n",
      "Epoch 438/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 8.6950e-05\n",
      "Epoch 439/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 8.5164e-05\n",
      "Epoch 440/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 8.3415e-05\n",
      "Epoch 441/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 8.1701e-05\n",
      "Epoch 442/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 8.0024e-05\n",
      "Epoch 443/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.8379e-05\n",
      "Epoch 444/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 7.6771e-05\n",
      "Epoch 445/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 7.5193e-05\n",
      "Epoch 446/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 7.3648e-05\n",
      "Epoch 447/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 7.2136e-05\n",
      "Epoch 448/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 7.0654e-05\n",
      "Epoch 449/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 6.9203e-05\n",
      "Epoch 450/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.7780e-05\n",
      "Epoch 451/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.6388e-05\n",
      "Epoch 452/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.5025e-05\n",
      "Epoch 453/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3689e-05\n",
      "Epoch 454/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.2381e-05\n",
      "Epoch 455/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.1100e-05\n",
      "Epoch 456/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 5.9846e-05\n",
      "Epoch 457/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 5.8617e-05\n",
      "Epoch 458/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 5.7412e-05\n",
      "Epoch 459/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 5.6233e-05\n",
      "Epoch 460/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 5.5078e-05\n",
      "Epoch 461/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 5.3946e-05\n",
      "Epoch 462/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 5.2839e-05\n",
      "Epoch 463/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 5.1753e-05\n",
      "Epoch 464/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 5.0689e-05\n",
      "Epoch 465/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.9648e-05\n",
      "Epoch 466/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.8628e-05\n",
      "Epoch 467/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.7628e-05\n",
      "Epoch 468/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 4.6651e-05\n",
      "Epoch 469/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.5693e-05\n",
      "Epoch 470/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 4.4754e-05\n",
      "Epoch 471/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 4.3834e-05\n",
      "Epoch 472/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.2934e-05\n",
      "Epoch 473/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 4.2053e-05\n",
      "Epoch 474/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.1189e-05\n",
      "Epoch 475/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.0343e-05\n",
      "Epoch 476/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.9514e-05\n",
      "Epoch 477/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.8702e-05\n",
      "Epoch 478/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.7908e-05\n",
      "Epoch 479/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.7129e-05\n",
      "Epoch 480/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.6367e-05\n",
      "Epoch 481/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.5620e-05\n",
      "Epoch 482/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.4888e-05\n",
      "Epoch 483/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.4172e-05\n",
      "Epoch 484/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.3470e-05\n",
      "Epoch 485/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.2783e-05\n",
      "Epoch 486/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.2108e-05\n",
      "Epoch 487/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.1449e-05\n",
      "Epoch 488/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.0803e-05\n",
      "Epoch 489/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.0171e-05\n",
      "Epoch 490/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 2.9551e-05\n",
      "Epoch 491/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.8944e-05\n",
      "Epoch 492/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.8350e-05\n",
      "Epoch 493/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.7767e-05\n",
      "Epoch 494/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.7197e-05\n",
      "Epoch 495/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.6638e-05\n",
      "Epoch 496/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 2.6091e-05\n",
      "Epoch 497/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.5555e-05\n",
      "Epoch 498/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.5030e-05\n",
      "Epoch 499/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.4516e-05\n",
      "Epoch 500/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.4012e-05\n",
      "Epoch 501/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.3519e-05\n",
      "Epoch 502/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.3037e-05\n",
      "Epoch 503/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 2.2563e-05\n",
      "Epoch 504/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.2099e-05\n",
      "Epoch 505/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.1645e-05\n",
      "Epoch 506/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.1201e-05\n",
      "Epoch 507/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.0766e-05\n",
      "Epoch 508/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.0339e-05\n",
      "Epoch 509/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.9922e-05\n",
      "Epoch 510/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.9512e-05\n",
      "Epoch 511/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.9112e-05\n",
      "Epoch 512/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.8719e-05\n",
      "Epoch 513/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.8334e-05\n",
      "Epoch 514/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.7958e-05\n",
      "Epoch 515/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.7589e-05\n",
      "Epoch 516/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.7228e-05\n",
      "Epoch 517/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.6874e-05\n",
      "Epoch 518/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.6527e-05\n",
      "Epoch 519/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.6188e-05\n",
      "Epoch 520/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.5856e-05\n",
      "Epoch 521/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.5530e-05\n",
      "Epoch 522/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.5210e-05\n",
      "Epoch 523/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.4898e-05\n",
      "Epoch 524/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.4592e-05\n",
      "Epoch 525/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.4292e-05\n",
      "Epoch 526/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.3999e-05\n",
      "Epoch 527/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.3712e-05\n",
      "Epoch 528/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.3429e-05\n",
      "Epoch 529/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.3154e-05\n",
      "Epoch 530/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.2883e-05\n",
      "Epoch 531/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.2619e-05\n",
      "Epoch 532/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.2360e-05\n",
      "Epoch 533/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.2106e-05\n",
      "Epoch 534/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1857e-05\n",
      "Epoch 535/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1614e-05\n",
      "Epoch 536/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.1376e-05\n",
      "Epoch 537/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.1142e-05\n",
      "Epoch 538/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.0913e-05\n",
      "Epoch 539/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.0689e-05\n",
      "Epoch 540/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.0469e-05\n",
      "Epoch 541/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.0254e-05\n",
      "Epoch 542/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.0043e-05\n",
      "Epoch 543/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 9.8370e-06\n",
      "Epoch 544/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 9.6349e-06\n",
      "Epoch 545/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 9.4372e-06\n",
      "Epoch 546/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 9.2429e-06\n",
      "Epoch 547/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 9.0528e-06\n",
      "Epoch 548/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 8.8671e-06\n",
      "Epoch 549/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 8.6853e-06\n",
      "Epoch 550/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 8.5069e-06\n",
      "Epoch 551/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 8.3322e-06\n",
      "Epoch 552/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 8.1611e-06\n",
      "Epoch 553/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.9935e-06\n",
      "Epoch 554/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.8289e-06\n",
      "Epoch 555/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.6682e-06\n",
      "Epoch 556/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 7.5108e-06\n",
      "Epoch 557/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 7.3568e-06\n",
      "Epoch 558/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.2055e-06\n",
      "Epoch 559/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.0578e-06\n",
      "Epoch 560/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.9127e-06\n",
      "Epoch 561/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.7708e-06\n",
      "Epoch 562/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.6319e-06\n",
      "Epoch 563/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.4958e-06\n",
      "Epoch 564/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 6.3621e-06\n",
      "Epoch 565/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 6.2311e-06\n",
      "Epoch 566/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.1033e-06\n",
      "Epoch 567/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 5.9777e-06\n",
      "Epoch 568/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 5.8548e-06\n",
      "Epoch 569/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 5.7347e-06\n",
      "Epoch 570/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 5.6169e-06\n",
      "Epoch 571/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 5.5015e-06\n",
      "Epoch 572/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 5.3884e-06\n",
      "Epoch 573/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 5.2778e-06\n",
      "Epoch 574/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 5.1691e-06\n",
      "Epoch 575/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 5.0631e-06\n",
      "Epoch 576/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.9592e-06\n",
      "Epoch 577/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.8574e-06\n",
      "Epoch 578/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 4.7577e-06\n",
      "Epoch 579/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 4.6598e-06\n",
      "Epoch 580/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 4.5640e-06\n",
      "Epoch 581/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 4.4703e-06\n",
      "Epoch 582/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.3786e-06\n",
      "Epoch 583/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 4.2889e-06\n",
      "Epoch 584/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 4.2006e-06\n",
      "Epoch 585/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 4.1144e-06\n",
      "Epoch 586/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 4.0299e-06\n",
      "Epoch 587/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.9472e-06\n",
      "Epoch 588/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.8661e-06\n",
      "Epoch 589/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.7867e-06\n",
      "Epoch 590/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.7087e-06\n",
      "Epoch 591/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.6325e-06\n",
      "Epoch 592/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.5581e-06\n",
      "Epoch 593/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.4850e-06\n",
      "Epoch 594/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.4134e-06\n",
      "Epoch 595/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.3432e-06\n",
      "Epoch 596/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.2746e-06\n",
      "Epoch 597/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.2075e-06\n",
      "Epoch 598/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.1414e-06\n",
      "Epoch 599/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.0770e-06\n",
      "Epoch 600/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.0137e-06\n",
      "Epoch 601/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.9519e-06\n",
      "Epoch 602/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 2.8912e-06\n",
      "Epoch 603/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.8320e-06\n",
      "Epoch 604/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.7737e-06\n",
      "Epoch 605/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.7169e-06\n",
      "Epoch 606/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 2.6609e-06\n",
      "Epoch 607/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.6064e-06\n",
      "Epoch 608/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.5528e-06\n",
      "Epoch 609/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.5003e-06\n",
      "Epoch 610/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.4492e-06\n",
      "Epoch 611/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 2.3988e-06\n",
      "Epoch 612/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.3497e-06\n",
      "Epoch 613/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.3013e-06\n",
      "Epoch 614/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.2539e-06\n",
      "Epoch 615/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.2077e-06\n",
      "Epoch 616/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.1623e-06\n",
      "Epoch 617/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 2.1180e-06\n",
      "Epoch 618/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.0746e-06\n",
      "Epoch 619/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.0318e-06\n",
      "Epoch 620/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.9901e-06\n",
      "Epoch 621/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.9492e-06\n",
      "Epoch 622/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.9092e-06\n",
      "Epoch 623/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.8700e-06\n",
      "Epoch 624/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.8315e-06\n",
      "Epoch 625/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.7940e-06\n",
      "Epoch 626/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.7570e-06\n",
      "Epoch 627/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.7211e-06\n",
      "Epoch 628/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.6856e-06\n",
      "Epoch 629/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.6511e-06\n",
      "Epoch 630/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.6171e-06\n",
      "Epoch 631/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.5840e-06\n",
      "Epoch 632/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.5513e-06\n",
      "Epoch 633/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.5195e-06\n",
      "Epoch 634/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.4882e-06\n",
      "Epoch 635/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.4577e-06\n",
      "Epoch 636/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.4278e-06\n",
      "Epoch 637/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.3983e-06\n",
      "Epoch 638/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.3697e-06\n",
      "Epoch 639/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.3415e-06\n",
      "Epoch 640/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 1.3140e-06\n",
      "Epoch 641/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.2869e-06\n",
      "Epoch 642/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.2605e-06\n",
      "Epoch 643/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.2345e-06\n",
      "Epoch 644/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.2092e-06\n",
      "Epoch 645/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.1845e-06\n",
      "Epoch 646/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.1600e-06\n",
      "Epoch 647/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.1361e-06\n",
      "Epoch 648/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.1129e-06\n",
      "Epoch 649/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.0901e-06\n",
      "Epoch 650/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.0675e-06\n",
      "Epoch 651/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.0456e-06\n",
      "Epoch 652/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 1.0241e-06\n",
      "Epoch 653/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.0032e-06\n",
      "Epoch 654/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 9.8254e-07\n",
      "Epoch 655/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 9.6228e-07\n",
      "Epoch 656/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 9.4256e-07\n",
      "Epoch 657/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 9.2315e-07\n",
      "Epoch 658/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 9.0434e-07\n",
      "Epoch 659/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 8.8575e-07\n",
      "Epoch 660/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 8.6749e-07\n",
      "Epoch 661/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 8.4976e-07\n",
      "Epoch 662/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 8.3227e-07\n",
      "Epoch 663/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 8.1507e-07\n",
      "Epoch 664/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 7.9844e-07\n",
      "Epoch 665/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 7.8194e-07\n",
      "Epoch 666/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 7.6596e-07\n",
      "Epoch 667/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 7.5024e-07\n",
      "Epoch 668/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 7.3480e-07\n",
      "Epoch 669/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 7.1966e-07\n",
      "Epoch 670/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 7.0491e-07\n",
      "Epoch 671/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 6.9040e-07\n",
      "Epoch 672/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 6.7608e-07\n",
      "Epoch 673/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 6.6222e-07\n",
      "Epoch 674/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 6.4861e-07\n",
      "Epoch 675/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 6.3528e-07\n",
      "Epoch 676/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 6.2219e-07\n",
      "Epoch 677/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 6.0933e-07\n",
      "Epoch 678/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 5.9690e-07\n",
      "Epoch 679/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 5.8457e-07\n",
      "Epoch 680/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 5.7259e-07\n",
      "Epoch 681/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 5.6088e-07\n",
      "Epoch 682/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 5.4932e-07\n",
      "Epoch 683/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 5.3803e-07\n",
      "Epoch 684/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 5.2697e-07\n",
      "Epoch 685/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 5.1613e-07\n",
      "Epoch 686/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 5.0549e-07\n",
      "Epoch 687/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 4.9521e-07\n",
      "Epoch 688/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 4.8508e-07\n",
      "Epoch 689/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 4.7500e-07\n",
      "Epoch 690/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 4.6527e-07\n",
      "Epoch 691/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 4.5577e-07\n",
      "Epoch 692/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 4.4646e-07\n",
      "Epoch 693/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 4.3726e-07\n",
      "Epoch 694/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 4.2828e-07\n",
      "Epoch 695/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 4.1954e-07\n",
      "Epoch 696/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 4.1080e-07\n",
      "Epoch 697/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 4.0245e-07\n",
      "Epoch 698/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 3.9412e-07\n",
      "Epoch 699/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.8610e-07\n",
      "Epoch 700/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 3.7807e-07\n",
      "Epoch 701/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 3.7036e-07\n",
      "Epoch 702/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.6277e-07\n",
      "Epoch 703/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.5528e-07\n",
      "Epoch 704/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.4798e-07\n",
      "Epoch 705/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.4083e-07\n",
      "Epoch 706/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.3388e-07\n",
      "Epoch 707/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.2699e-07\n",
      "Epoch 708/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.2030e-07\n",
      "Epoch 709/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.1372e-07\n",
      "Epoch 710/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.0723e-07\n",
      "Epoch 711/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.0094e-07\n",
      "Epoch 712/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 2.9480e-07\n",
      "Epoch 713/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 2.8865e-07\n",
      "Epoch 714/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 2.8280e-07\n",
      "Epoch 715/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 2.7696e-07\n",
      "Epoch 716/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 2.7124e-07\n",
      "Epoch 717/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 2.6572e-07\n",
      "Epoch 718/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 2.6029e-07\n",
      "Epoch 719/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 2.5489e-07\n",
      "Epoch 720/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 2.4971e-07\n",
      "Epoch 721/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 2.4453e-07\n",
      "Epoch 722/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 2.3957e-07\n",
      "Epoch 723/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 2.3466e-07\n",
      "Epoch 724/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 2.2982e-07\n",
      "Epoch 725/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 2.2507e-07\n",
      "Epoch 726/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 2.2045e-07\n",
      "Epoch 727/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 2.1596e-07\n",
      "Epoch 728/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 2.1153e-07\n",
      "Epoch 729/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 2.0720e-07\n",
      "Epoch 730/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 2.0291e-07\n",
      "Epoch 731/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.9877e-07\n",
      "Epoch 732/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.9466e-07\n",
      "Epoch 733/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.9071e-07\n",
      "Epoch 734/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.8679e-07\n",
      "Epoch 735/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.8296e-07\n",
      "Epoch 736/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.7916e-07\n",
      "Epoch 737/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1.7549e-07\n",
      "Epoch 738/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 1.7194e-07\n",
      "Epoch 739/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.6843e-07\n",
      "Epoch 740/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.6492e-07\n",
      "Epoch 741/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.6158e-07\n",
      "Epoch 742/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.5823e-07\n",
      "Epoch 743/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.5500e-07\n",
      "Epoch 744/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.5184e-07\n",
      "Epoch 745/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.4876e-07\n",
      "Epoch 746/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.4563e-07\n",
      "Epoch 747/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.4268e-07\n",
      "Epoch 748/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.3975e-07\n",
      "Epoch 749/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.3681e-07\n",
      "Epoch 750/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.3402e-07\n",
      "Epoch 751/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.3126e-07\n",
      "Epoch 752/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.2859e-07\n",
      "Epoch 753/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 1.2596e-07\n",
      "Epoch 754/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.2336e-07\n",
      "Epoch 755/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.2080e-07\n",
      "Epoch 756/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.1834e-07\n",
      "Epoch 757/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.1592e-07\n",
      "Epoch 758/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.1353e-07\n",
      "Epoch 759/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1119e-07\n",
      "Epoch 760/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.0889e-07\n",
      "Epoch 761/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.0667e-07\n",
      "Epoch 762/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.0446e-07\n",
      "Epoch 763/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.0234e-07\n",
      "Epoch 764/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.0022e-07\n",
      "Epoch 765/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 9.8155e-08\n",
      "Epoch 766/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 9.6129e-08\n",
      "Epoch 767/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 9.4182e-08\n",
      "Epoch 768/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 9.2243e-08\n",
      "Epoch 769/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 9.0356e-08\n",
      "Epoch 770/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 8.8493e-08\n",
      "Epoch 771/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 8.6704e-08\n",
      "Epoch 772/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 8.4888e-08\n",
      "Epoch 773/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 8.3144e-08\n",
      "Epoch 774/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 8.1427e-08\n",
      "Epoch 775/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 7.9744e-08\n",
      "Epoch 776/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 7.8137e-08\n",
      "Epoch 777/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 7.6541e-08\n",
      "Epoch 778/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 7.4954e-08\n",
      "Epoch 779/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 7.3454e-08\n",
      "Epoch 780/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 7.1929e-08\n",
      "Epoch 781/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 7.0484e-08\n",
      "Epoch 782/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 6.8994e-08\n",
      "Epoch 783/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 6.7575e-08\n",
      "Epoch 784/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 6.6177e-08\n",
      "Epoch 785/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 6.4836e-08\n",
      "Epoch 786/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 6.3524e-08\n",
      "Epoch 787/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 6.2222e-08\n",
      "Epoch 788/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 6.0928e-08\n",
      "Epoch 789/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 5.9660e-08\n",
      "Epoch 790/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 5.8461e-08\n",
      "Epoch 791/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 5.7247e-08\n",
      "Epoch 792/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 5.6071e-08\n",
      "Epoch 793/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 5.4922e-08\n",
      "Epoch 794/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 5.3793e-08\n",
      "Epoch 795/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 5.2678e-08\n",
      "Epoch 796/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 5.1598e-08\n",
      "Epoch 797/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 5.0539e-08\n",
      "Epoch 798/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 4.9503e-08\n",
      "Epoch 799/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 4.8487e-08\n",
      "Epoch 800/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 4.7517e-08\n",
      "Epoch 801/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 4.6512e-08\n",
      "Epoch 802/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 4.5576e-08\n",
      "Epoch 803/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 4.4650e-08\n",
      "Epoch 804/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 4.3739e-08\n",
      "Epoch 805/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 4.2838e-08\n",
      "Epoch 806/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 4.1951e-08\n",
      "Epoch 807/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 4.1074e-08\n",
      "Epoch 808/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 4.0244e-08\n",
      "Epoch 809/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.9410e-08\n",
      "Epoch 810/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 3.8596e-08\n",
      "Epoch 811/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 3.7802e-08\n",
      "Epoch 812/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.7013e-08\n",
      "Epoch 813/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 3.6276e-08\n",
      "Epoch 814/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.5546e-08\n",
      "Epoch 815/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.4791e-08\n",
      "Epoch 816/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 3.4076e-08\n",
      "Epoch 817/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 3.3380e-08\n",
      "Epoch 818/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 3.2701e-08\n",
      "Epoch 819/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 3.2018e-08\n",
      "Epoch 820/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 3.1380e-08\n",
      "Epoch 821/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.0724e-08\n",
      "Epoch 822/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 3.0101e-08\n",
      "Epoch 823/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 2.9483e-08\n",
      "Epoch 824/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 2.8876e-08\n",
      "Epoch 825/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 2.8277e-08\n",
      "Epoch 826/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 2.7729e-08\n",
      "Epoch 827/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 2.7136e-08\n",
      "Epoch 828/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 2.6599e-08\n",
      "Epoch 829/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 2.6038e-08\n",
      "Epoch 830/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 2.5502e-08\n",
      "Epoch 831/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 2.4986e-08\n",
      "Epoch 832/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 2.4478e-08\n",
      "Epoch 833/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 2.3969e-08\n",
      "Epoch 834/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 2.3468e-08\n",
      "Epoch 835/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 2.2986e-08\n",
      "Epoch 836/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 2.2527e-08\n",
      "Epoch 837/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 2.2046e-08\n",
      "Epoch 838/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 2.1607e-08\n",
      "Epoch 839/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 2.1158e-08\n",
      "Epoch 840/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 2.0729e-08\n",
      "Epoch 841/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 2.0324e-08\n",
      "Epoch 842/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.9893e-08\n",
      "Epoch 843/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.9486e-08\n",
      "Epoch 844/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.9091e-08\n",
      "Epoch 845/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.8711e-08\n",
      "Epoch 846/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.8315e-08\n",
      "Epoch 847/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 1.7946e-08\n",
      "Epoch 848/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.7581e-08\n",
      "Epoch 849/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.7228e-08\n",
      "Epoch 850/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.6867e-08\n",
      "Epoch 851/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.6521e-08\n",
      "Epoch 852/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.6182e-08\n",
      "Epoch 853/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.5835e-08\n",
      "Epoch 854/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.5525e-08\n",
      "Epoch 855/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.5201e-08\n",
      "Epoch 856/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.4872e-08\n",
      "Epoch 857/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.4573e-08\n",
      "Epoch 858/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.4277e-08\n",
      "Epoch 859/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.3987e-08\n",
      "Epoch 860/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 1.3694e-08\n",
      "Epoch 861/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 1.3428e-08\n",
      "Epoch 862/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 1.3151e-08\n",
      "Epoch 863/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.2870e-08\n",
      "Epoch 864/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.2619e-08\n",
      "Epoch 865/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.2344e-08\n",
      "Epoch 866/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.2101e-08\n",
      "Epoch 867/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.1867e-08\n",
      "Epoch 868/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.1607e-08\n",
      "Epoch 869/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.1368e-08\n",
      "Epoch 870/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.1138e-08\n",
      "Epoch 871/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.0910e-08\n",
      "Epoch 872/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.0685e-08\n",
      "Epoch 873/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.0462e-08\n",
      "Epoch 874/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 1.0248e-08\n",
      "Epoch 875/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.0054e-08\n",
      "Epoch 876/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 9.8344e-09\n",
      "Epoch 877/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 9.6239e-09\n",
      "Epoch 878/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 9.4357e-09\n",
      "Epoch 879/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 9.2349e-09\n",
      "Epoch 880/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 9.0363e-09\n",
      "Epoch 881/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 8.8678e-09\n",
      "Epoch 882/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 8.6681e-09\n",
      "Epoch 883/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 8.4926e-09\n",
      "Epoch 884/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 8.3228e-09\n",
      "Epoch 885/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 8.1618e-09\n",
      "Epoch 886/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 7.9917e-09\n",
      "Epoch 887/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 7.8245e-09\n",
      "Epoch 888/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 7.6755e-09\n",
      "Epoch 889/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 7.5232e-09\n",
      "Epoch 890/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 7.3653e-09\n",
      "Epoch 891/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 7.2042e-09\n",
      "Epoch 892/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 7.0642e-09\n",
      "Epoch 893/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 6.9232e-09\n",
      "Epoch 894/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 6.7836e-09\n",
      "Epoch 895/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 6.6477e-09\n",
      "Epoch 896/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 6.4999e-09\n",
      "Epoch 897/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 6.3668e-09\n",
      "Epoch 898/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 6.2425e-09\n",
      "Epoch 899/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 6.1121e-09\n",
      "Epoch 900/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 5.9863e-09\n",
      "Epoch 901/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 5.8586e-09\n",
      "Epoch 902/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 5.7504e-09\n",
      "Epoch 903/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 5.6373e-09\n",
      "Epoch 904/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 5.5181e-09\n",
      "Epoch 905/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 5.3975e-09\n",
      "Epoch 906/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 5.2835e-09\n",
      "Epoch 907/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 5.1808e-09\n",
      "Epoch 908/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 5.0644e-09\n",
      "Epoch 909/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 4.9684e-09\n",
      "Epoch 910/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 4.8583e-09\n",
      "Epoch 911/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 4.7608e-09\n",
      "Epoch 912/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 4.6637e-09\n",
      "Epoch 913/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 4.5622e-09\n",
      "Epoch 914/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 4.4770e-09\n",
      "Epoch 915/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 4.3875e-09\n",
      "Epoch 916/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 4.2963e-09\n",
      "Epoch 917/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 4.2094e-09\n",
      "Epoch 918/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 4.1228e-09\n",
      "Epoch 919/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 4.0344e-09\n",
      "Epoch 920/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 3.9482e-09\n",
      "Epoch 921/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.8791e-09\n",
      "Epoch 922/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.7953e-09\n",
      "Epoch 923/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.7272e-09\n",
      "Epoch 924/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.6414e-09\n",
      "Epoch 925/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.5750e-09\n",
      "Epoch 926/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.4947e-09\n",
      "Epoch 927/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.4313e-09\n",
      "Epoch 928/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 3.3644e-09\n",
      "Epoch 929/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.2901e-09\n",
      "Epoch 930/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.2231e-09\n",
      "Epoch 931/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.1620e-09\n",
      "Epoch 932/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.1015e-09\n",
      "Epoch 933/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.0364e-09\n",
      "Epoch 934/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 2.9768e-09\n",
      "Epoch 935/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 2.9182e-09\n",
      "Epoch 936/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 2.8595e-09\n",
      "Epoch 937/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 2.8023e-09\n",
      "Epoch 938/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 2.7450e-09\n",
      "Epoch 939/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 2.6887e-09\n",
      "Epoch 940/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 2.6324e-09\n",
      "Epoch 941/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 2.5775e-09\n",
      "Epoch 942/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 2.5226e-09\n",
      "Epoch 943/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 2.4717e-09\n",
      "Epoch 944/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 2.4208e-09\n",
      "Epoch 945/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 2.3677e-09\n",
      "Epoch 946/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 2.3188e-09\n",
      "Epoch 947/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 2.2777e-09\n",
      "Epoch 948/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 2.2260e-09\n",
      "Epoch 949/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 2.1753e-09\n",
      "Epoch 950/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 2.1357e-09\n",
      "Epoch 951/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 2.0891e-09\n",
      "Epoch 952/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 2.0409e-09\n",
      "Epoch 953/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 2.0070e-09\n",
      "Epoch 954/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.9601e-09\n",
      "Epoch 955/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.9244e-09\n",
      "Epoch 956/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.8851e-09\n",
      "Epoch 957/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.8499e-09\n",
      "Epoch 958/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.8048e-09\n",
      "Epoch 959/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.7708e-09\n",
      "Epoch 960/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.7328e-09\n",
      "Epoch 961/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.6994e-09\n",
      "Epoch 962/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.6642e-09\n",
      "Epoch 963/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.6254e-09\n",
      "Epoch 964/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.5989e-09\n",
      "Epoch 965/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.5671e-09\n",
      "Epoch 966/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.5326e-09\n",
      "Epoch 967/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.5022e-09\n",
      "Epoch 968/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.4719e-09\n",
      "Epoch 969/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.4420e-09\n",
      "Epoch 970/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.4105e-09\n",
      "Epoch 971/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.3780e-09\n",
      "Epoch 972/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.3558e-09\n",
      "Epoch 973/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.3280e-09\n",
      "Epoch 974/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.2986e-09\n",
      "Epoch 975/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.2771e-09\n",
      "Epoch 976/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.2485e-09\n",
      "Epoch 977/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.2275e-09\n",
      "Epoch 978/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.1994e-09\n",
      "Epoch 979/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1787e-09\n",
      "Epoch 980/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.1527e-09\n",
      "Epoch 981/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.1254e-09\n",
      "Epoch 982/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.1055e-09\n",
      "Epoch 983/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.0809e-09\n",
      "Epoch 984/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.0622e-09\n",
      "Epoch 985/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.0417e-09\n",
      "Epoch 986/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.0233e-09\n",
      "Epoch 987/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.0052e-09\n",
      "Epoch 988/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 9.8175e-10\n",
      "Epoch 989/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 9.6397e-10\n",
      "Epoch 990/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 9.4640e-10\n",
      "Epoch 991/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 9.2367e-10\n",
      "Epoch 992/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 9.0649e-10\n",
      "Epoch 993/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 8.8947e-10\n",
      "Epoch 994/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 8.7053e-10\n",
      "Epoch 995/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 8.5385e-10\n",
      "Epoch 996/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 8.3809e-10\n",
      "Epoch 997/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 8.2253e-10\n",
      "Epoch 998/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 8.0601e-10\n",
      "Epoch 999/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 7.9168e-10\n",
      "Epoch 1000/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 7.7651e-10\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x28cac334cd0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A simple linear regression NN with one layer\n",
    "\n",
    "# build a one-layer one-neuron NN\n",
    "layer_1 = keras.layers.Dense(units=1, input_shape=[1])\n",
    "model = tf.keras.Sequential([layer_1])\n",
    "\n",
    "# compile model\n",
    "model.compile(optimizer='sgd', loss='mean_squared_error') # 'mse'\n",
    "\n",
    "# data: y = 2x - 1\n",
    "xs = np.array([-1.0,  0.0, 1.0, 2.0, 3.0, 4.0], dtype=float)\n",
    "ys = np.array([-3.0, -1.0, 1.0, 3.0, 5.0, 7.0], dtype=float) \n",
    "\n",
    "# train NN\n",
    "model.fit(xs, ys, epochs=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_pred when x=10.0 [[18.999914]]\n",
      "Parameters: [array([[1.9999878]], dtype=float32), array([-0.99996364], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "# using NN, predict y when x=10.0\n",
    "print(\"y_pred when x=10.0\", model.predict([10.0]))\n",
    "\n",
    "print(\"Parameters: {}\".format(layer_1.get_weights()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A Multi-Layer NN for Multi-Class Classification on MNIST Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load and prepare the [MNIST dataset](http://yann.lecun.com/exdb/mnist/). Convert the samples from integers to floating-point numbers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 0s 0us/step\n",
      "11501568/11490434 [==============================] - 0s 0us/step\n"
     ]
    }
   ],
   "source": [
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.14901961, 0.74901961, 0.54117647, 0.09411765, 0.09411765,\n",
       "        0.42352941, 0.54117647, 0.13333333, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.2745098 , 0.98823529, 0.98823529, 0.99215686, 0.98823529,\n",
       "        0.98823529, 0.98823529, 0.98823529, 0.63529412, 0.34509804,\n",
       "        0.05098039, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.2       , 0.94117647, 0.98823529, 0.99215686, 0.94117647,\n",
       "        0.71764706, 0.71764706, 0.96470588, 0.99215686, 0.98823529,\n",
       "        0.79215686, 0.55686275, 0.02745098, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.14509804, 0.38431373, 0.82745098, 0.80784314,\n",
       "        0.        , 0.        , 0.16470588, 0.42745098, 0.69411765,\n",
       "        0.98823529, 0.98823529, 0.82745098, 0.16862745, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.05098039, 0.07058824,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.01960784,\n",
       "        0.21176471, 0.70196078, 0.98823529, 0.8627451 , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.16862745, 0.94509804, 1.        , 0.36078431,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.90196078, 0.99215686, 0.36078431,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.26666667, 0.96470588, 0.96862745, 0.2627451 ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.5254902 , 0.98823529, 0.36862745, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.45490196, 0.97254902, 0.78431373, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.05098039, 0.38039216,\n",
       "        0.87058824, 0.75294118, 0.04313725, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.14901961, 0.38823529, 0.81568627, 0.89019608,\n",
       "        0.68235294, 0.06666667, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.81176471, 0.98823529, 0.92941176, 0.34509804,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.31372549, 0.79215686, 0.99215686, 0.95686275,\n",
       "        0.81176471, 0.31372549, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.04313725, 0.37647059, 0.98823529,\n",
       "        0.98823529, 0.95686275, 0.28627451, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.08627451,\n",
       "        0.78039216, 0.97647059, 0.99215686, 0.50196078, 0.03529412,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.4627451 , 0.97254902, 0.99215686, 0.44313725,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.45098039, 0.99215686, 0.94117647,\n",
       "        0.19607843, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.99215686, 0.98823529,\n",
       "        0.27058824, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.99215686, 0.90588235,\n",
       "        0.14509804, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build a multi-layer NN for multi-class classification\n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Flatten(input_shape=(28, 28)), # input layer - Use Flatten to make it a 1D vector\n",
    "  tf.keras.layers.Dense(128, activation='relu'), # hidden layer with 128 neurons\n",
    "  tf.keras.layers.Dropout(0.2), # dropout is a regularization technique\n",
    "  tf.keras.layers.Dense(10, activation='softmax')]) # output layer has 10 neurons and softmax activation function\n",
    "\n",
    "# compile model for multi-class classification\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy', # loss='SparseCategoricalCrossentropy'\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Notes**:\n",
    "\n",
    "> These classifiers process vectors, which are 1D, whereas the current input is a rank-3 tensor (60000, 28, 28). To bridge the gap, we flatten the 3D inputs to 1D with a `Flatten` layer before adding the `Dense` layers.\n",
    "\n",
    "> Use `loss='sparse_categorical_crossentropy'` loss function when there are two or more label classes. `tf` expects labels to be provided as integers. If you want to provide labels using `one-hot` representation, use `CategoricalCrossentropy` loss.\n",
    "\n",
    "> Read more about the [`SparseCategoricalCrossentropy`](https://www.tensorflow.org/api_docs/python/tf/keras/losses/SparseCategoricalCrossentropy) and [`CategoricalCrossentropy`](https://www.tensorflow.org/api_docs/python/tf/keras/losses/CategoricalCrossentropy) in their tf documentations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_1 (Flatten)         (None, 784)               0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 128)               100480    \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 101,770\n",
      "Trainable params: 101,770\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0641 - accuracy: 0.9801\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0566 - accuracy: 0.9812\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 5s 2ms/step - loss: 0.0514 - accuracy: 0.9833\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0455 - accuracy: 0.9848\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0448 - accuracy: 0.9858\n",
      "313/313 - 1s - loss: 0.0676 - accuracy: 0.9796 - 1s/epoch - 3ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.06763247400522232, 0.9796000123023987]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train NN\n",
    "model.fit(x_train, y_train, epochs=5)\n",
    "\n",
    "# test NN\n",
    "model.evaluate(x_test,  y_test, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The image classifier is now trained to ~98% accuracy on this dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eager Execution in Tensorflow 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensorflow 2 has this new capability of [\"Eager Execution\"](https://www.tensorflow.org/guide/eager) which makes it more convenient to work with tensors and graph computations. See examples below and compare it with tensorflow 1 which uses Session() and Run() to execute these operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.Variable(3, name=\"x\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = tf.Variable(4, name=\"y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = x*x*y + y + 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'x:0' shape=() dtype=int32, numpy=3>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'y:0' shape=() dtype=int32, numpy=4>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=42>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(42, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "print(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "4\n",
      "42\n"
     ]
    }
   ],
   "source": [
    "print(x.numpy())\n",
    "print(y.numpy())\n",
    "print(f.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the model using the Sequential API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let’s review the steps in building a neural network! Here is a classification MLP with two hidden\n",
    "layers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build a NN for MNIST\n",
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape=[28, 28])) # the input layer\n",
    "model.add(keras.layers.Dense(300, activation=\"relu\")) # the first hidden layer with 300 neurons\n",
    "model.add(keras.layers.Dense(100, activation=\"relu\")) # the 2nd hidden layer with 100 neurons\n",
    "model.add(keras.layers.Dense(10, activation=\"softmax\")) # the output layer: it's a 10-class classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s go through this code line by line:\n",
    "- The first line creates a Sequential model. This is the simplest kind of Keras model for neural networks that are just composed of a single stack of layers connected sequentially. This is called the Sequential API.\n",
    "\n",
    "- Next, we build the first layer and add it to the model. It is a `Flatten` layer whose role is to convert each input image into a 1D array: if it receives input data X , it computes `X.reshape(-1, 1)`. This layer does not have any parameters; it is just there to do some simple preprocessing. Since it is the first layer in the model, you should specify the `input_shape` , which doesn’t include the batch size, only the shape of the instances. Alternatively, you could add a `keras.layers.InputLayer` as the first layer, setting `input_shape=[28,28]`\n",
    "\n",
    "- Next we add a `Dense` hidden layer with 300 neurons. It will use the ReLU activation function. Each Dense layer manages its own weight matrix, containing all the connection weights between the neurons and their inputs. It also manages a vector of bias terms (one per neuron). When it receives some input data, it computes Equation 10-2.\n",
    "\n",
    "$$h_{\\mathbf{W}, \\mathbf{b}}(\\mathbf{X}) = \\phi (\\mathbf{X} \\mathbf{W} + \\mathbf{b})$$\n",
    "\n",
    "- Then we add a second `Dense` hidden layer with 100 neurons, also using the ReLU activation function.\n",
    "\n",
    "- Finally, we add a `Dense` output layer with 10 neurons (one per class), using the\n",
    "softmax activation function (because the classes are exclusive)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Specifying `activation=\"relu\"` is equivalent to specifying `activation=keras.activations.relu`. Other activation functions are available in the keras.activations package. See https://keras.io/activations/ for the full list.\n",
    "\n",
    "> Instead of adding the layers one by one as we just did, you can pass a list of layers when creating the Sequential model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "keras.layers.Flatten(input_shape=[28, 28]),\n",
    "keras.layers.Dense(300, activation=\"relu\"),\n",
    "keras.layers.Dense(100, activation=\"relu\"),\n",
    "keras.layers.Dense(10, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fashion MNIST Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is [another example of image classification](https://github.com/zalandoresearch/fashion-mnist)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
      "32768/29515 [=================================] - 0s 0us/step\n",
      "40960/29515 [=========================================] - 0s 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
      "26427392/26421880 [==============================] - 0s 0us/step\n",
      "26435584/26421880 [==============================] - 0s 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
      "16384/5148 [===============================================================================================] - 0s 0s/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
      "4423680/4422102 [==============================] - 0s 0us/step\n",
      "4431872/4422102 [==============================] - 0s 0us/step\n"
     ]
    }
   ],
   "source": [
    "fashion_mnist = keras.datasets.fashion_mnist\n",
    "\n",
    "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9, 0, 0, ..., 3, 0, 5], dtype=uint8)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAATEAAAD4CAYAAACE9dGgAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAc3UlEQVR4nO3dfXBd9X3n8fdXsuQHWX7CRhhwYiAmiZMshnXAASYloQ0Pk6lhkzIwXeK0TM3uwjZ0+APKdifsdNjJZAM0bRq2JrAxMxBKAxSXesKDQ0JICsEYBz8tsQET2/gRg21sy5auvvvHPVquLJ3vOdK90r1H/ryYM7463/u756cj6ct5+J7fz9wdEZGiaqp3B0REqqEkJiKFpiQmIoWmJCYihaYkJiKFNmYkN9ZqY30cbSO5SZHjSicHOepHrJrPuOQLbf7u3lKu977y2pGn3P3SarZXraqSmJldCnwXaAZ+4O7fit4/jjbOs4ur2aSIBF7yFVV/xp69JV566tRc722Z+cb0qjdYpSGfTppZM/D3wGXAXOAaM5tbq46JSL04Je/JtWQxs1lm9pyZrTezdWb2jWT97Wa2zcxWJ8vlFW3+0sw2mdnrZnZJ1jaqORI7F9jk7m8mG34YWAisr+IzRaTOHOihZkXw3cDN7r7KzNqBV8zsmSR2t7t/p/LNyYHQ1cCngJOBZ83sTHdPPb+t5sL+KcCWiq+3Juv6MLPFZrbSzFZ2caSKzYnISOnJ+V8Wd9/u7quS1weADQyQJyosBB529yPu/hawifIBU6phvzvp7kvcfb67z29h7HBvTkSq5Dhd3pNrAab3HqQky+K0zzWz2cDZwEvJqhvN7DUzu9/Mpibrch0cVarmdHIbMKvi61OTdSJSYA6U8p9O7nH3+VlvMrOJwKPATe6+38zuAf462dxfA3cCfzqU/lZzJPYyMMfMTjOzVsrnscuq+DwRaRA9eK4lDzNroZzAHnT3xwDcfae7l9y9B7iXD08ZB31wNOQk5u7dwI3AU5TPcx9x93VD/TwRaQwOlNxzLVnMzID7gA3uflfF+pkVb7sSWJu8XgZcbWZjzew0YA7w62gbVdWJuftyYHk1nyEijSf7kn1uFwDXAmvMbHWy7jbKJVnzKOfMzcD1AO6+zsweoVzl0A3cEN2ZhBGu2BeRxuf4YK6JxZ/l/gIw0BMEqQc/7n4HcEfebSiJiUgf7tBVoLFSlcRE5BhGacCDp8akJCYifTjQoyMxESkyHYmJSGGVi12VxESkoBzo8uKMl6okJiJ9OEapQIM+K4mJSD89rtNJESkoXRMTkYIzSromJiJFVR7ZVUlMRArK3TjqzfXuRm5KYqOdZVzbyDGcSqT5hGlh/L1LzkyNTXroxaq2nfW92ZiW1Jh3Ha1u29XK+rlEqvyZ5dGja2IiUlTlC/s6nRSRwtKFfREpMF3YF5HCK6nYVUSKyjG6vDipoTg9FZERoQv7IlJojul0UhqHNcdFi97dHcab5s0N4xuunxi3P5weazkYzk7PmMPxnDstT68M41XVgmXVoGXsVyw+kqmmbzYm+LONf5y56cK+iBSWOyqxEJHiKl/Y12NHIlJgurAvIoXlmAZFFJFi05GYiBRWed5JJTERKSzNAC4NJKwpIrtObMslU8L4H3/uF2H8l7tPT429PfaksK2PD8OM+f3PhfEzv78tNda9+Xfxh2eM2ZW137I0T52aHiyVwral/fvTgzUYaqw8ZdtxcnfSzDYDB4AS0O3u82vRKRGpH3c77k4nv+Due2rwOSLSIFTsKiKFVR5P7Pi5JubA02bmwD+4+5Jj32Bmi4HFAOOYUOXmRGT4FWtk12p7eqG7nwNcBtxgZp8/9g3uvsTd57v7/BbGVrk5ERlu5RILy7VkMbNZZvacma03s3Vm9o1k/TQze8bMNib/Tk3Wm5n9rZltMrPXzOycrG1UlcTcfVvy7y7gcSAelkBEGl7vs5N5lhy6gZvdfS6wgPLBzlzgVmCFu88BViRfQ/mAaE6yLAbuydrAkJOYmbWZWXvva+BLwNqhfp6INI4emnItWdx9u7uvSl4fADYApwALgaXJ25YCVySvFwIPeNmLwBQzmxlto5prYh3A41Yed2kM8JC7/6SKz5Nh0NPZWVX7o2d/EMa/Ojke02tcU1dq7OdN8Xhh2346K4yX/l3ct7fvak+N9bx6ftj2hLVxrdakV7eH8T2fPyWM7/736QVdHRnTcU599o3UmO2t/l5deSie3Bf2p5tZ5S/BkoGujQOY2WzgbOAloMPde3fiDsr5BMoJbktFs63JutQdPuTv2N3fBM4aansRaVyDeAB8T576UDObCDwK3OTu+61i0El39+Tm4JCoxEJE+iiPYlG7u5Nm1kI5gT3o7o8lq3ea2Ux3356cLu5K1m8DKg/BT03WpSrOfVQRGRHlx46aci1ZrHzIdR+wwd3vqggtAxYlrxcBT1Ss/1pyl3IBsK/itHNAOhITkWPU9EjsAuBaYI2ZrU7W3QZ8C3jEzK4D3gauSmLLgcuBTcAh4E+yNqAkJiL91Kpi391fgNQPu3iA9ztww2C2oSQmIn0M8u5k3SmJjQbR9GIZQ8p8cNWCMP61uT8L4290zQjjp7buTY390cmvhG35j3H8e6//Xhg/+Obk1FhTW7xfdiyIT6e2LYy/b++Kh+qZuir9T69p0c6w7f6j6cMblVbU5qmY420UCxEZRTTGvogUmgPdOhITkSLT6aSIFFfOESoahZKYiPRxvA2KKCKjkI7ERKSwegdFLAolsUYQ1XkNswW3/DqMf2Hi+qo+/5RgDrGD3hq2fb/UFsa/Ofdfw/juM9OH4uny+Ff/BxvjoXo+CGrQAJq745/pgj99NTX2lWkvh22//ehnUmNNfjBsm4djdPfowr6IFJiuiYlIcblOJ0WkwHRNTEQKT0lMRArLMUq6sC8iRaYL+yJSWK4L+zJoGWN+DaeNH5wYxt+dNDGM7+ieEsZPaE6fVq296XDYdnbLnjC+u5ReBwbQ3JI+JdzRjIlf/8en/iWMd36yJYy3WDzl2/nj3kmN/dH6r4Vt23gzjNeCK4mJSHHpAXARKTgdiYlIYblDqUdJTEQKTHcnRaSwHJ1Oikih6cK+iBRcHat+Bk1J7Dg3Y2x6HRfAOOsK460Wz6/4TtfU1NjGwx8P2/52f1zDdmnHujDeFdSCNQfjnEF2ndfJLe+F8U6P68iivXpBR1wHtjqM1kaRTiczH5Ays/vNbJeZra1YN83MnjGzjcm/6b+pIlIo5buTTbmWRpCnFz8ELj1m3a3ACnefA6xIvhaRUcI939IIMpOYuz8PHDsX/UJgafJ6KXBFbbslIvXkbrmWRjDUa2Id7r49eb0D6Eh7o5ktBhYDjGPCEDcnIiPFaZwElUfVJ7Xu7pB+ldTdl7j7fHef38LYajcnIiPAcy6NYKhHYjvNbKa7bzezmcCuWnZKROrIwQv02NFQj8SWAYuS14uAJ2rTHRFpBKPqmpiZ/Qi4CJhuZluBbwLfAh4xs+uAt4GrhrOTo17GvJPWHI995d3ptVrNU+Pql9+bsiaM7y5NCuPvl+LrnFOaD6XGDnSPC9vuPRx/9ifGbg/jqw7NTo3NaI3rvKJ+A2w+Oj2Mzxm7I4x/e+fFqbFZ4469j9ZX98WfT435S/8Wts2rUe485pGZxNz9mpRQ+k9BRAqrls9Omtn9wJeBXe7+6WTd7cCfAbuTt93m7suT2F8C1wEl4M/d/amsbTRGtZqINA4H3PIt2X5I/zpTgLvdfV6y9CawucDVwKeSNt83s/g0BCUxERlArYpdU+pM0ywEHnb3I+7+FrAJODerkZKYiBzD8J58C+Vr5SsrlsU5N3Kjmb2WPNbYe+H2FGBLxXu2JutCSmIi0l/+QrE9vXWgybIkx6ffA5wBzAO2A3dW01WNYiEiffnwjmLh7jt7X5vZvcCTyZfbgFkVbz01WRdSEmsEGRcXbEz8Y4pKLLZc98mw7RcnxFOT/aozPpqfMeZAGI+Gw5k5dl/Ytr2jM4xnlXdMG5M+zNCB0viw7YSmI2E86/s+pzWebu4vnj0nNdb+6XfDtpNaghOoWuWeYSyx6C2UT768EugdIWcZ8JCZ3QWcDMwBfp31eUpiIjKAmpVYDFRnepGZzaOcKjcD1wO4+zozewRYD3QDN7h7PLAbSmIiMpD0eYcHJaXO9L7g/XcAdwxmG0piItJXb51YQSiJiUg/o+qxIxE5DimJiUih6XRSRIrMdCQmg2EtrWG8pzOul4pMX3M0jO8pxVOLTWmKh6RpzZja7GhQJ3b+tLfCtrszarlWHT4tjLc3H06NzWiK67xmtcS1Wms6Z4Xx5Qc/Fsav+/KzqbEfLfmDsG3rT36VGjOPf165uEGBBkVUEhOR/nQkJiKFpiQmIoWmJCYihaViVxEpOt2dFJFiUxITkSLTkdhwCaY2szFxvZM1Zwxi2xTHezqD8aV6MkcLCXlXXMtVje/+w/fC+JbuKWF8R1ccz5rarBQM6fLi4clh23FNXWF8xpj9YXx/T1xnFjnQE08nF42TBtl9v+WEjamxx/b9fth2ROiamIgU1odDTxeCkpiI9KckJiJFZjUaFHEkKImJSH86EhORojLX3UkRKTrdnRSRQtOR2NBUM79iVq2Vx2U7dXV44blhfMsVcR3aH5+dPjXfju72sO2rh2aH8cnBmFwAbRnzM3Z6ev3eO0enpsYgu9YqmlcS4MSgjqzkcV3gtq64b1my6ue2dgdzYv5hPNbZlAeG1KVBKdLpZEYFKJjZ/Wa2y8zWVqy73cy2mdnqZLl8eLspIiPGy3cn8yyNIDOJAT8ELh1g/d3uPi9Zlte2WyJSV55zaQCZSczdnwf2jkBfRKRRjKYkFrjRzF5LTjdTLyCY2WIzW2lmK7uIr5+ISGPoLbPIWhrBUJPYPcAZwDxgO3Bn2hvdfYm7z3f3+S2MHeLmREQGNqQk5u473b3k7j3AvUB8e01EimW0n06a2cyKL68E1qa9V0QKpmB3JzPrxMzsR8BFwHQz2wp8E7jIzOZRzsWbgetr0ZmoDqxaY2aeFMa7TusI43s/OSE1duikuLp53uUbwvjXO/5PGN9dmhTGWyx9v23pOiFse/aEzWH8p/vmhvE9YyaG8ajO7Py29DG1AN7vSd/nACePeS+M37Lpq6mxjglxLdYPPhrfcO/y+C/49a740sm+nvTxyP587nNh28eZEcZrokGOsvLITGLufs0Aq+8bhr6ISAMwGueifR4NVbEvIg1CSUxECquByifyqKZOTERGq56cS4aUxxanmdkzZrYx+Xdqst7M7G/NbFNSg3pOnq4qiYlIPzUsdv0h/R9bvBVY4e5zgBXJ1wCXAXOSZTHletRMSmIi0l+N6sRSHltcCCxNXi8FrqhY/4CXvQhMOaaca0ANdU3syGWfDeMn/rc3U2PzJm0N284d/0IY7+yJp3yLhoVZf/iUsO2hntYwvvFoXP6xrzsuNWgOCnZ2HY2H4rnzrXh6sBXn/u8w/lfvDDQ2wIeaxqf/pr9bisszvjIxnpIN4p/Z9R95PjV2euuusO2TB+O/nXcyhurpaNkXxme37E6N/Yf234Zth73EYvgLWTvcfXvyegfQW990CrCl4n1bk3XbCTRUEhORxjCIC/vTzWxlxddL3H1J3sbu7mbV3UZQEhOR/vKnlT3uPn+Qn77TzGa6+/bkdLH3sHgbMKvifacm60K6JiYi/QzzY0fLgEXJ60XAExXrv5bcpVwA7Ks47UylIzER6auG18RSHlv8FvCImV0HvA1clbx9OXA5sAk4BPxJnm0oiYlIH5YstZDy2CLAxQO814EbBrsNJTER6a9AFftKYiLST5EeOxrZJGbxtGzn/c+Xw+YXt69LjR3yeOiTrDqwrLqfyOQx8fRcR7ri3byrKx5qJ8uZY3ekxq6ctDps+/z3zgvjF3b+1zD+xhfjYYRWHE4fcmZ3d/x9X/3WF8P4qt/NCuMLZr+VGvtMe3zTK6s2r725M4xHwyMBHOxJ/319sTOunxsRSmIiUljeOAMe5qEkJiL96UhMRIpM18REpNiUxESkyHQkJiLF5eQa8LBRKImJSB+aKCTQdWIb71ybPs/u7ZP/Lmz/0N4FqbFZ444dd62vj7buCeNnjX87jEfam+KaoY9PimuGnjx4ahj/2fufCOMzW95Pjf3i0Blh24dv/19h/Ot/cXMY/9zy/xTG989OH2Oguy3+S5l01rth/K/O/tcw3mql1Nj7pbgObNrYg2F8SnNcG5glqmtsb0qf5g6g+eMfS43Z5njcvNyUxESkyMyLk8WUxESkr+Ef2bWmlMREpB9dExORQtNjRyJSbDoSE5HCKtgM4EpiItKfktjAmrpgws70k+0n988L258+Pn2uvj1d8fyKT33wmTB+6vj3wvjk5vTanY8F43kBrO6cEsZ/svtTYfzk8fH8izu7JqfG3u1qC9seCsa1Arjv7rvC+J0743krr5y2KjV2VmtcB/Z+TzyPzfqM+ToP9IxLjXV6PL7cvow6svbg9wGgy+M/rWZP/zuY0hTXoO3/zAmpsdLO6v+ki1bsmjnbkZnNMrPnzGy9ma0zs28k66eZ2TNmtjH5d+ijCopIQ7Eez7U0gjxTtnUDN7v7XGABcIOZzQVuBVa4+xxgRfK1iBSdD2JpAJlJzN23u/uq5PUBYAPlqcUXAkuTty0FrhimPorICBvmeSdralAn0GY2GzgbeAnoqJjYcgfQkdJmMbAYoLVNZ5wihdAgR1l55J4B3MwmAo8CN7l7nyvNyXxxA37b7r7E3ee7+/wxY+OLzCLSGMzzLY0gVxIzsxbKCexBd38sWb3TzGYm8ZnAruHpooiMKAfc8y0NIPN00swMuA/Y4O6V99uXAYsoT0m+CHgi67Oaj/bQvuVIarzH43mHf7onfUiajnEHwrbz2reE8dcPxbfr1xw+OTW2asxHwrbjm7vC+OTWeCiftjHp+wxgekv6937a2Pj/LdFwNQAvd8bf23+e8bMw/rvu9EsI/3LwzLDt+kPp+xxgasZUeWv2p7c/1N0atj1Siv80Orvjkp3JY+Of6WenpQ/99Dozw7a7zwqGN/pl2DS3RrnelUeea2IXANcCa8xsdbLuNsrJ6xEzuw54G7hqWHooIiOqaHVimUnM3V+g/H0N5OLadkdE6q6BThXz0GNHItLPqDoSE5HjkJKYiBSZjsREpLgcKBUniymJiUg/OhJL88Fhmn7+amr4n56+IGz+3xf+U2rs5xnTmj25I67r2X80HpJmxoT0KbwmBXVaANNa4um/JmfUO42zeMq397rTn4Q40hQPOVNKvfFctuNI+jA/AL/smRPGu3qaU2NHghhk19ftPTo9jJ88fl9q7EB3+jA9AJsPTAvje/ZNDOOdE+I/rRdK6VPpXXrSurDt+F3pP7Om+FclP92dFJEiq+WRmJltBg4AJaDb3eeb2TTgH4HZwGbgKnePB/VLkfvZSRE5TgzPUDxfcPd57j4/+bpmQ3kpiYlIHwZYyXMtVajZUF5KYiLSj7nnWoDpZrayYlk8wMc58LSZvVIRzzWUVx66JiYifQ3uVHFPxSlimgvdfZuZnQg8Y2b/t8/m3N1s6FfhdCQmIsfIOQxPzjuY7r4t+XcX8DhwLjUcyktJTET6qdWgiGbWZmbtva+BLwFr+XAoL8g5lFeahjqdPP2Wfwvj33/tq+lt/8vrYdvLTlobxlftj8fN+l1QN/SbYKwxgJameHCmCS1Hw/i4jHqp1ub0McGaMs4LejLqxNqa475ljXU2bWx6jVx7czzmVlOVg1o1B9/7r/fNDtt2TIhr/z42aU8Y7/b4+OBzk99Ijd3/1vlh246/+1VqbLPHNYm51a5OrAN4vDwsIWOAh9z9J2b2MjUayquhkpiINACn2juPH36U+5vAWQOsf5caDeWlJCYi/RWnYF9JTET6Mz12JCKFpiQmIoXlwCibKEREjiOG63RSRAqupziHYiOfxJqCMaR64jkQJz/4Ymrs3Qfjzf74K5eE8fNuezmMf3n2b1Jjn2jdGbZtyTg2H5dRD9XWFNdydQb/18yqZn7h8KwwXsr4hJ++98kw/n7X+NTYzkOTwrYtQf1bHtE8poe743HW9h2OxxtrboqPVDp/Fo919tb69PHvJi+PfxeHnU4nRaTodDopIsWmJCYixaXJc0WkyDTbkYgUna6JiUixKYmJSGE50DOKkpiZzQIeoDwukANL3P27ZnY78GfA7uStt7n78swtZtSCDZe2R18K42sfjduv5bTUmH32D8O2h09Kr5UCGPtuPCbXgY/G7Se9kT6GVNOReCLCnt9sCOPZPqii7f4wGo+iVp3WjPiMqrfw26o/oX5G34X9buBmd1+VjND4ipk9k8TudvfvDF/3RKQuRlMSS2Yk2Z68PmBmG4BThrtjIlInDpSKU7I/qDH2zWw2cDbQe252o5m9Zmb3m9nUlDaLe6dz6iI+bRKRRuDgPfmWBpA7iZnZROBR4CZ33w/cA5wBzKN8pHbnQO3cfYm7z3f3+S2Mrb7HIjL8ajjb0XDLdXfSzFooJ7AH3f0xAHffWRG/F3hyWHooIiOrYHcnM4/ErDxNyX3ABne/q2L9zIq3XUl5GiYRGQ1G2ZHYBcC1wBozW52suw24xszmUc7bm4Hrh6F/heAvrwnj8aAu2Salz9CVqTGuWkjhNEiCyiPP3ckXYMDJCbNrwkSkeNyhVJ96zqFQxb6I9DeajsRE5DikJCYixeWFujupJCYifTl4gxSy5qEkJiL9FeixIyUxEenLXVO2iUjB6cK+iBSZ60hMRIqrcR4pykNJTET6KtgD4EpiItKHA16gx44GNSiiiBwHvLaDIprZpWb2upltMrNba91dHYmJSD9eo9NJM2sG/h74A2Ar8LKZLXP39TXZADoSE5GB1O5I7Fxgk7u/6e5HgYeBhbXs6ogeiR3gvT3P+o/frlg1Hdgzkn0YhEbtW6P2C9S3oapl3z5a7Qcc4L2nnvUfT8/59nFmtrLi6yXuvqTi61OALRVfbwXOq7aPlUY0ibl7n+n8zGylu88fyT7k1ah9a9R+gfo2VI3WN3e/tN59GAydTorIcNoGzKr4+tRkXc0oiYnIcHoZmGNmp5lZK3A1sKyWG6j33ckl2W+pm0btW6P2C9S3oWrkvlXF3bvN7EbgKaAZuN/d19VyG+YFerxARORYOp0UkUJTEhORQqtLEhvuxxCqYWabzWyNma0+pv6lHn2538x2mdnainXTzOwZM9uY/Du1gfp2u5ltS/bdajO7vE59m2Vmz5nZejNbZ2bfSNbXdd8F/WqI/VZUI35NLHkM4bdUPIYAXFPLxxCqYWabgfnuXvfCSDP7PPAB8IC7fzpZ921gr7t/K/kfwFR3v6VB+nY78IG7f2ek+3NM32YCM919lZm1A68AVwBfp477LujXVTTAfiuqehyJDftjCKOFuz8P7D1m9UJgafJ6KeU/ghGX0reG4O7b3X1V8voAsIFy5Xhd913QL6lCPZLYQI8hNNIP0oGnzewVM1tc784MoMPdtyevdwAd9ezMAG40s9eS0826nOpWMrPZwNnASzTQvjumX9Bg+61IdGG/vwvd/RzgMuCG5LSpIXn5WkAj1cjcA5wBzAO2A3fWszNmNhF4FLjJ3fdXxuq57wboV0Ptt6KpRxIb9scQquHu25J/dwGPUz79bSQ7k2srvddYdtW5P/+fu+9095KXJy28lzruOzNroZwoHnT3x5LVdd93A/WrkfZbEdUjiQ37YwhDZWZtyQVXzKwN+BKwNm414pYBi5LXi4An6tiXPnoTROJK6rTvzMyA+4AN7n5XRaiu+y6tX42y34qqLhX7yS3kv+HDxxDuGPFODMDMTqd89AXlR7IeqmffzOxHwEWUh2rZCXwT+GfgEeAjwNvAVe4+4hfYU/p2EeVTIgc2A9dXXIMayb5dCPwCWAP0Dnp1G+XrT3Xbd0G/rqEB9ltR6bEjESk0XdgXkUJTEhORQlMSE5FCUxITkUJTEhORQlMSE5FCUxITkUL7fxCZI/LPsbAHAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.imshow(train_images[0])\n",
    "plt.colorbar()\n",
    "plt.grid(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = train_images / 255.0\n",
    "\n",
    "test_images = test_images / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 25 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "for i in range(25):\n",
    "    plt.subplot(5,5,i+1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    plt.imshow(train_images[i], cmap=plt.cm.binary)\n",
    "    plt.xlabel(class_names[train_labels[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build a multi-class classification NN\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dense(10, activation='softmax')]) # the output layer has 10 neurons and softmax activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1688/1688 [==============================] - 4s 2ms/step - loss: 0.5035 - accuracy: 0.8258 - val_loss: 0.4089 - val_accuracy: 0.8515\n",
      "Epoch 2/10\n",
      "1688/1688 [==============================] - 3s 2ms/step - loss: 0.3796 - accuracy: 0.8631 - val_loss: 0.4136 - val_accuracy: 0.8537\n",
      "Epoch 3/10\n",
      "1688/1688 [==============================] - 3s 2ms/step - loss: 0.3381 - accuracy: 0.8774 - val_loss: 0.4346 - val_accuracy: 0.8348\n",
      "Epoch 4/10\n",
      "1688/1688 [==============================] - 3s 2ms/step - loss: 0.3145 - accuracy: 0.8850 - val_loss: 0.3356 - val_accuracy: 0.8758\n",
      "Epoch 5/10\n",
      "1688/1688 [==============================] - 6s 3ms/step - loss: 0.2994 - accuracy: 0.8898 - val_loss: 0.3485 - val_accuracy: 0.8717\n",
      "Epoch 6/10\n",
      "1688/1688 [==============================] - 4s 2ms/step - loss: 0.2821 - accuracy: 0.8956 - val_loss: 0.3334 - val_accuracy: 0.8810\n",
      "Epoch 7/10\n",
      "1688/1688 [==============================] - 4s 3ms/step - loss: 0.2721 - accuracy: 0.8989 - val_loss: 0.3456 - val_accuracy: 0.8787\n",
      "Epoch 8/10\n",
      "1688/1688 [==============================] - 4s 2ms/step - loss: 0.2608 - accuracy: 0.9028 - val_loss: 0.3175 - val_accuracy: 0.8845\n",
      "Epoch 9/10\n",
      "1688/1688 [==============================] - 4s 2ms/step - loss: 0.2512 - accuracy: 0.9062 - val_loss: 0.3232 - val_accuracy: 0.8845\n",
      "Epoch 10/10\n",
      "1688/1688 [==============================] - 4s 2ms/step - loss: 0.2408 - accuracy: 0.9107 - val_loss: 0.3266 - val_accuracy: 0.8847\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_images, train_labels, validation_split=0.1, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> The `fit()` method returns a History object containing the training parameters `history.params`, the list of epochs it went through `history.epoch`, and most importantly a dictionary `history.history` containing the loss and extra metrics it measured at the end of each epoch on the training set and on the validation set (if any)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'verbose': 1, 'epochs': 10, 'steps': 1688}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n"
     ]
    }
   ],
   "source": [
    "print(history.epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> If you use this dictionary to create a pandas `DataFrame` and call its `plot()` method, you get the learning curves:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 1.0)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame(history.history).plot(figsize=(8, 5))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0, 1) # set the vertical range to [0-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 - 1s - loss: 0.3458 - accuracy: 0.8784 - 983ms/epoch - 3ms/step\n",
      "\n",
      "Test accuracy: 0.8784000277519226\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=2)\n",
    "\n",
    "print('\\nTest accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ignore the warning if any\n",
    "predictions = model.predict(test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.4378237e-06, 3.6920170e-07, 1.9985675e-06, 1.7534465e-05,\n",
       "       5.0463960e-08, 4.3162864e-04, 4.1788126e-06, 1.4241762e-02,\n",
       "       2.6688534e-07, 9.8529983e-01], dtype=float32)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(predictions[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> You can read more on MNIST fashion example [here](https://www.tensorflow.org/tutorials/keras/classification)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### California House Pricing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we're going to build a regression model for Califronia house pricing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetch data\n",
    "housing = fetch_california_housing()\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(\n",
    "housing.data, housing.target)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "X_train_full, y_train_full)\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_valid = scaler.transform(X_valid)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11610, 8)\n",
      "(5160, 8)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 2s 4ms/step - loss: 1.1111 - val_loss: 0.5417\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.4914 - val_loss: 0.4415\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 2s 4ms/step - loss: 0.4390 - val_loss: 0.4123\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.4180 - val_loss: 0.4043\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4063 - val_loss: 0.3876\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 2s 4ms/step - loss: 0.3958 - val_loss: 0.3861\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3883 - val_loss: 0.3739\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3840 - val_loss: 0.3712\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3795 - val_loss: 0.3718\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3751 - val_loss: 0.3638\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3722 - val_loss: 0.3644\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3694 - val_loss: 0.3648\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3688 - val_loss: 0.3631\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3657 - val_loss: 0.3611\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3640 - val_loss: 0.3549\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3609 - val_loss: 0.3542\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3581 - val_loss: 0.3644\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3589 - val_loss: 0.3550\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3564 - val_loss: 0.3547\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3572 - val_loss: 0.3551\n"
     ]
    }
   ],
   "source": [
    "# build a regression NN\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"relu\", input_shape=X_train.shape[1:]),\n",
    "    keras.layers.Dense(1) # output layer with 1 neuron and with None activation function because it's regression\n",
    "])\n",
    "\n",
    "# compile NN\n",
    "model.compile(loss=\"mean_squared_error\", optimizer=\"sgd\")\n",
    "history = model.fit(X_train, y_train, epochs=20, validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 0s 2ms/step - loss: 0.3437\n"
     ]
    }
   ],
   "source": [
    "mse_test = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new = X_test[:3] # pretend these are new instances\n",
    "y_pred = model.predict(X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.07651627],\n",
       "       [6.023957  ],\n",
       "       [3.4127908 ]], dtype=float32)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving and Restoring the Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When using the Sequential API or the Functional API, saving a trained Keras model is as simple as it gets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"my_keras_model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will typically have a script that trains a model and saves it, and one or more scripts (or web services) that load the model and use it to make predictions. Loading the model is just as easy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model(\"my_keras_model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Callbacks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if training lasts several hours? This is quite common, especially when training on large datasets.\n",
    "\n",
    "In this case, you should not only save your model at the end of training, but also save **checkpoints** at regular intervals during training, to avoid losing everything if your computer crashes.\n",
    "\n",
    "How can you tell the `fit()` method to save **checkpoints**? Use **callbacks**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `fit()` method accepts a `callbacks` argument that lets you specify a list of objects that Keras will call at the start and end of training, at the start and end of each epoch, and even before and after processing each batch. For example, the `ModelCheckpoint` callback saves checkpoints of your model at regular intervals during training, by default at the end of each epoch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Moreover, if you use a validation set during training, you can set `save_best_only=True` when creating the `ModelCheckpoint` .\n",
    "\n",
    "In this case, it will only save your model when its performance on the validation set is the best so far. This way, you do not need to worry about training for too long and overfitting the training set: simply restore the last model saved after training, and this will be the best model on the validation set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build model\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"relu\", input_shape=[8]),\n",
    "    keras.layers.Dense(30, activation=\"relu\"),\n",
    "    keras.layers.Dense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile model\n",
    "model.compile(loss=\"mse\", optimizer=keras.optimizers.SGD(learning_rate=1e-3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code is a simple way to implement **early stopping**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create checkpoint\n",
    "checkpoint_cb = keras.callbacks.ModelCheckpoint(\"my_keras_model.h5\", save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "363/363 [==============================] - 2s 3ms/step - loss: 2.1880 - val_loss: 0.9890\n",
      "Epoch 2/10\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.8320 - val_loss: 0.7537\n",
      "Epoch 3/10\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.7090 - val_loss: 0.6884\n",
      "Epoch 4/10\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.6597 - val_loss: 0.6451\n",
      "Epoch 5/10\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.6264 - val_loss: 0.6198\n",
      "Epoch 6/10\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5976 - val_loss: 0.6108\n",
      "Epoch 7/10\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.5727 - val_loss: 0.5645\n",
      "Epoch 8/10\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.5514 - val_loss: 0.5451\n",
      "Epoch 9/10\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5344 - val_loss: 0.5334\n",
      "Epoch 10/10\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5180 - val_loss: 0.5209\n"
     ]
    }
   ],
   "source": [
    "# train with callbacks and validation_data\n",
    "history = model.fit(X_train, y_train, epochs=10,\n",
    "                    validation_data=(X_valid, y_valid),\n",
    "                    callbacks=[checkpoint_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 0s 2ms/step - loss: 0.4883\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.load_model(\"my_keras_model.h5\") # rollback to best model\n",
    "mse_test = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Another way to implement **early stopping** is to simply use the `EarlyStopping` callback. It will interrupt training when it measures no progress on the validation set for a number of epochs (defined by the `patience` argument), and it will optionally roll back to the best model.\n",
    "\n",
    "> You can combine both callbacks to save checkpoints of your model (in case your computer crashes) and interrupt training early when there is no more progress (to avoid wasting time and resources):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "363/363 [==============================] - 2s 4ms/step - loss: 0.5046 - val_loss: 0.5100\n",
      "Epoch 2/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.4940 - val_loss: 0.4964\n",
      "Epoch 3/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4805 - val_loss: 0.4759\n",
      "Epoch 4/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.4740 - val_loss: 0.4685\n",
      "Epoch 5/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.4670 - val_loss: 0.4636\n",
      "Epoch 6/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.4596 - val_loss: 0.4617\n",
      "Epoch 7/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.4533 - val_loss: 0.4489\n",
      "Epoch 8/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.4493 - val_loss: 0.4521\n",
      "Epoch 9/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4452 - val_loss: 0.4415\n",
      "Epoch 10/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.4408 - val_loss: 0.4372\n",
      "Epoch 11/100\n",
      "363/363 [==============================] - 2s 4ms/step - loss: 0.4377 - val_loss: 0.4347\n",
      "Epoch 12/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4344 - val_loss: 0.4264\n",
      "Epoch 13/100\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.4310 - val_loss: 0.4310\n",
      "Epoch 14/100\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.4274 - val_loss: 0.4212\n",
      "Epoch 15/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.4266 - val_loss: 0.4190\n",
      "Epoch 16/100\n",
      "363/363 [==============================] - 2s 7ms/step - loss: 0.4248 - val_loss: 0.4160\n",
      "Epoch 17/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.4202 - val_loss: 0.4171\n",
      "Epoch 18/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.4176 - val_loss: 0.4135\n",
      "Epoch 19/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.4167 - val_loss: 0.4128\n",
      "Epoch 20/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.4131 - val_loss: 0.4090\n",
      "Epoch 21/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.4108 - val_loss: 0.4053\n",
      "Epoch 22/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.4080 - val_loss: 0.4030\n",
      "Epoch 23/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.4061 - val_loss: 0.4025\n",
      "Epoch 24/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.4047 - val_loss: 0.4010\n",
      "Epoch 25/100\n",
      "363/363 [==============================] - 3s 8ms/step - loss: 0.4028 - val_loss: 0.3977\n",
      "Epoch 26/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.4006 - val_loss: 0.3955\n",
      "Epoch 27/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3987 - val_loss: 0.3930\n",
      "Epoch 28/100\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3974 - val_loss: 0.3914\n",
      "Epoch 29/100\n",
      "363/363 [==============================] - 3s 8ms/step - loss: 0.3960 - val_loss: 0.3903\n",
      "Epoch 30/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3941 - val_loss: 0.3899\n",
      "Epoch 31/100\n",
      "363/363 [==============================] - 2s 7ms/step - loss: 0.3923 - val_loss: 0.3912\n",
      "Epoch 32/100\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.3911 - val_loss: 0.3907\n",
      "Epoch 33/100\n",
      "363/363 [==============================] - 3s 8ms/step - loss: 0.3892 - val_loss: 0.3851\n",
      "Epoch 34/100\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3880 - val_loss: 0.3829\n",
      "Epoch 35/100\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3876 - val_loss: 0.3826\n",
      "Epoch 36/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3856 - val_loss: 0.3807\n",
      "Epoch 37/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3847 - val_loss: 0.3809\n",
      "Epoch 38/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3833 - val_loss: 0.3785\n",
      "Epoch 39/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3826 - val_loss: 0.3792\n",
      "Epoch 40/100\n",
      "363/363 [==============================] - 2s 7ms/step - loss: 0.3808 - val_loss: 0.3790\n",
      "Epoch 41/100\n",
      "363/363 [==============================] - 5s 15ms/step - loss: 0.3795 - val_loss: 0.3750\n",
      "Epoch 42/100\n",
      "363/363 [==============================] - 4s 11ms/step - loss: 0.3792 - val_loss: 0.3743\n",
      "Epoch 43/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3773 - val_loss: 0.3775\n",
      "Epoch 44/100\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.3770 - val_loss: 0.3753\n",
      "Epoch 45/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3754 - val_loss: 0.3707\n",
      "Epoch 46/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3743 - val_loss: 0.3703\n",
      "Epoch 47/100\n",
      "363/363 [==============================] - 4s 11ms/step - loss: 0.3740 - val_loss: 0.3698\n",
      "Epoch 48/100\n",
      "363/363 [==============================] - 4s 11ms/step - loss: 0.3727 - val_loss: 0.3710\n",
      "Epoch 49/100\n",
      "363/363 [==============================] - 3s 9ms/step - loss: 0.3719 - val_loss: 0.3679\n",
      "Epoch 50/100\n",
      "363/363 [==============================] - 3s 8ms/step - loss: 0.3707 - val_loss: 0.3720\n",
      "Epoch 51/100\n",
      "363/363 [==============================] - 3s 8ms/step - loss: 0.3700 - val_loss: 0.3667\n",
      "Epoch 52/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3702 - val_loss: 0.3662\n",
      "Epoch 53/100\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3683 - val_loss: 0.3692\n",
      "Epoch 54/100\n",
      "363/363 [==============================] - 3s 8ms/step - loss: 0.3674 - val_loss: 0.3642\n",
      "Epoch 55/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3666 - val_loss: 0.3773\n",
      "Epoch 56/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3677 - val_loss: 0.3640\n",
      "Epoch 57/100\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3653 - val_loss: 0.3633\n",
      "Epoch 58/100\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3647 - val_loss: 0.3619\n",
      "Epoch 59/100\n",
      "363/363 [==============================] - 2s 7ms/step - loss: 0.3640 - val_loss: 0.3615\n",
      "Epoch 60/100\n",
      "363/363 [==============================] - 2s 7ms/step - loss: 0.3637 - val_loss: 0.3622\n",
      "Epoch 61/100\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3622 - val_loss: 0.3596\n",
      "Epoch 62/100\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3620 - val_loss: 0.3599\n",
      "Epoch 63/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3609 - val_loss: 0.3582\n",
      "Epoch 64/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3604 - val_loss: 0.3595\n",
      "Epoch 65/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3590 - val_loss: 0.3583\n",
      "Epoch 66/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3588 - val_loss: 0.3566\n",
      "Epoch 67/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3580 - val_loss: 0.3577\n",
      "Epoch 68/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3572 - val_loss: 0.3585\n",
      "Epoch 69/100\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3570 - val_loss: 0.3568\n",
      "Epoch 70/100\n",
      "363/363 [==============================] - 2s 7ms/step - loss: 0.3560 - val_loss: 0.3550\n",
      "Epoch 71/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3562 - val_loss: 0.3545\n",
      "Epoch 72/100\n",
      "363/363 [==============================] - 3s 7ms/step - loss: 0.3557 - val_loss: 0.3532\n",
      "Epoch 73/100\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3544 - val_loss: 0.3566\n",
      "Epoch 74/100\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3544 - val_loss: 0.3537\n",
      "Epoch 75/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3535 - val_loss: 0.3521\n",
      "Epoch 76/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3527 - val_loss: 0.3545\n",
      "Epoch 77/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3527 - val_loss: 0.3532\n",
      "Epoch 78/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3524 - val_loss: 0.3509\n",
      "Epoch 79/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3514 - val_loss: 0.3585\n",
      "Epoch 80/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3506 - val_loss: 0.3498\n",
      "Epoch 81/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3508 - val_loss: 0.3501\n",
      "Epoch 82/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3498 - val_loss: 0.3532\n",
      "Epoch 83/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3499 - val_loss: 0.3490\n",
      "Epoch 84/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3489 - val_loss: 0.3479\n",
      "Epoch 85/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3488 - val_loss: 0.3482\n",
      "Epoch 86/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3478 - val_loss: 0.3471\n",
      "Epoch 87/100\n",
      "363/363 [==============================] - 2s 7ms/step - loss: 0.3475 - val_loss: 0.3465\n",
      "Epoch 88/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3469 - val_loss: 0.3464\n",
      "Epoch 89/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3466 - val_loss: 0.3463\n",
      "Epoch 90/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3469 - val_loss: 0.3457\n",
      "Epoch 91/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3462 - val_loss: 0.3473\n",
      "Epoch 92/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3451 - val_loss: 0.3513\n",
      "Epoch 93/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3456 - val_loss: 0.3451\n",
      "Epoch 94/100\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.3448 - val_loss: 0.3443\n",
      "Epoch 95/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3444 - val_loss: 0.3448\n",
      "Epoch 96/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3440 - val_loss: 0.3433\n",
      "Epoch 97/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3430 - val_loss: 0.3460\n",
      "Epoch 98/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3425 - val_loss: 0.3430\n",
      "Epoch 99/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3428 - val_loss: 0.3431\n",
      "Epoch 100/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3423 - val_loss: 0.3420\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.3344\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=\"mse\", optimizer=keras.optimizers.SGD(lr=1e-3))\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=10,\n",
    "                                                  restore_best_weights=True)\n",
    "history = model.fit(X_train, y_train, epochs=100,\n",
    "                    validation_data=(X_valid, y_valid),\n",
    "                    callbacks=[checkpoint_cb, early_stopping_cb])\n",
    "mse_test = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> If you need extra control, you can easily write your own custom callbacks. As an example of how to do that, the following custom callback will display the ratio between the validation loss and the training loss during training (e.g., to detect over‐fitting):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PrintValTrainRatioCallback(keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs):\n",
    "        print(\"\\nval/train: {:.2f}\".format(logs[\"val_loss\"] / logs[\"loss\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "346/363 [===========================>..] - ETA: 0s - loss: 0.3424\n",
      "val/train: 1.00\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.3423 - val_loss: 0.3416\n"
     ]
    }
   ],
   "source": [
    "val_train_ratio_cb = PrintValTrainRatioCallback()\n",
    "history = model.fit(X_train, y_train, epochs=1,\n",
    "                    validation_data=(X_valid, y_valid),\n",
    "                    callbacks=[val_train_ratio_cb])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A neat feature of Tensorflow and Keras is visulaization through Tensorboard. The following code shows how you can visualize your training using Tensorboard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "root_logdir = os.path.join(os.curdir, \"my_logs\")\n",
    "def get_run_logdir():\n",
    "    import time\n",
    "    run_id = time.strftime(\"run_%Y_%m_%d-%H_%M_%S\")\n",
    "    return os.path.join(root_logdir, run_id)\n",
    "run_logdir = get_run_logdir() # e.g., './my_logs/run_2019_06_07-15_15_22'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3312 - val_loss: 0.3330\n",
      "Epoch 2/30\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3310 - val_loss: 0.3335\n",
      "Epoch 3/30\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3301 - val_loss: 0.3345\n",
      "Epoch 4/30\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.3301 - val_loss: 0.3314\n",
      "Epoch 5/30\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.3297 - val_loss: 0.3315\n",
      "Epoch 6/30\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.3304 - val_loss: 0.3310\n",
      "Epoch 7/30\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3298 - val_loss: 0.3306\n",
      "Epoch 8/30\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3292 - val_loss: 0.3305\n",
      "Epoch 9/30\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3296 - val_loss: 0.3304\n",
      "Epoch 10/30\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3288 - val_loss: 0.3297\n",
      "Epoch 11/30\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.3288 - val_loss: 0.3302\n",
      "Epoch 12/30\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3282 - val_loss: 0.3323\n",
      "Epoch 13/30\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.3287 - val_loss: 0.3297\n",
      "Epoch 14/30\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.3272 - val_loss: 0.3290\n",
      "Epoch 15/30\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3271 - val_loss: 0.3289\n",
      "Epoch 16/30\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.3279 - val_loss: 0.3287\n",
      "Epoch 17/30\n",
      "363/363 [==============================] - 3s 7ms/step - loss: 0.3270 - val_loss: 0.3287\n",
      "Epoch 18/30\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.3276 - val_loss: 0.3281\n",
      "Epoch 19/30\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.3269 - val_loss: 0.3289\n",
      "Epoch 20/30\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3268 - val_loss: 0.3276\n",
      "Epoch 21/30\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3254 - val_loss: 0.3275\n",
      "Epoch 22/30\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3265 - val_loss: 0.3264\n",
      "Epoch 23/30\n",
      "363/363 [==============================] - 3s 8ms/step - loss: 0.3259 - val_loss: 0.3276\n",
      "Epoch 24/30\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3248 - val_loss: 0.3268\n",
      "Epoch 25/30\n",
      "363/363 [==============================] - 2s 4ms/step - loss: 0.3257 - val_loss: 0.3271\n",
      "Epoch 26/30\n",
      "363/363 [==============================] - 4s 11ms/step - loss: 0.3244 - val_loss: 0.3260\n",
      "Epoch 27/30\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.3252 - val_loss: 0.3267\n",
      "Epoch 28/30\n",
      "363/363 [==============================] - 2s 4ms/step - loss: 0.3249 - val_loss: 0.3270\n",
      "Epoch 29/30\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3250 - val_loss: 0.3264\n",
      "Epoch 30/30\n",
      "363/363 [==============================] - 3s 10ms/step - loss: 0.3236 - val_loss: 0.3251\n"
     ]
    }
   ],
   "source": [
    "# Tensorboard Visualization\n",
    "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)\n",
    "history = model.fit(X_train, y_train, epochs=30, validation_data=(X_valid, y_valid), callbacks=[tensorboard_cb])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Next, run the following command at the root of the project directory where `my_logs` has been saved (or from anywhere else, as long as you point to the appropriate log directory):\n",
    "\n",
    "> `$ tensorboard --logdir=./my_logs --port=6006`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> And finally, once the server is up, you can open a web browser and go to:\n",
    "\n",
    "> http://localhost:6006"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise-1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise-1 has 10 points**.\n",
    "\n",
    "In this exercise you'll try to build a neural network that predicts the price of a house according to a simple formula.\n",
    "\n",
    "- Imagine if house pricing was as easy as a house costs 50k + 50k per bedroom, so that a 1 bedroom house costs 100k, a 2 bedroom house costs 150k and so on.\n",
    "\n",
    "- How would you create a neural network that learns this relationship so that it would predict a 7 bedroom house as costing close to 400k.\n",
    "\n",
    "**Hint**: Your network might work better if you scale the house price down. You don't have to give the answer 400...it might be better to create something that predicts the number 4, and then your answer is in the 'hundreds of thousands'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create data with at least 6 data points for x and y\n",
    "xs = np.array([1, 2, 3, 10, 15, 12], dtype=float)\n",
    "ys = np.array([.5, 1, 1.5, 5, 7.5, 6  ], dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build model with one layer and one neuron\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(units=1, input_shape=[1])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile model - be careful to use the correct loss for regression\n",
    "model.compile(optimizer='sgd', loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 75.6009\n",
      "Epoch 2/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 29.3273\n",
      "Epoch 3/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 11.3777\n",
      "Epoch 4/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 4.4150\n",
      "Epoch 5/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.7141\n",
      "Epoch 6/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6664\n",
      "Epoch 7/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.2600\n",
      "Epoch 8/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1023\n",
      "Epoch 9/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0411\n",
      "Epoch 10/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0174\n",
      "Epoch 11/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0081\n",
      "Epoch 12/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0045\n",
      "Epoch 13/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0031\n",
      "Epoch 14/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0026\n",
      "Epoch 15/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0023\n",
      "Epoch 16/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0022\n",
      "Epoch 17/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0021\n",
      "Epoch 18/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0021\n",
      "Epoch 19/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0021\n",
      "Epoch 20/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0020\n",
      "Epoch 21/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0020\n",
      "Epoch 22/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0020\n",
      "Epoch 23/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0019\n",
      "Epoch 24/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0019\n",
      "Epoch 25/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0019\n",
      "Epoch 26/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0019\n",
      "Epoch 27/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0018\n",
      "Epoch 28/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0018\n",
      "Epoch 29/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0018\n",
      "Epoch 30/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0018\n",
      "Epoch 31/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0017\n",
      "Epoch 32/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0017\n",
      "Epoch 33/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0017\n",
      "Epoch 34/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0017\n",
      "Epoch 35/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0016\n",
      "Epoch 36/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0016\n",
      "Epoch 37/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0016\n",
      "Epoch 38/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0016\n",
      "Epoch 39/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0015\n",
      "Epoch 40/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0015\n",
      "Epoch 41/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0015\n",
      "Epoch 42/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0015\n",
      "Epoch 43/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0015\n",
      "Epoch 44/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0014\n",
      "Epoch 45/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0014\n",
      "Epoch 46/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0014\n",
      "Epoch 47/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0014\n",
      "Epoch 48/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0014\n",
      "Epoch 49/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0013\n",
      "Epoch 50/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0013\n",
      "Epoch 51/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0013\n",
      "Epoch 52/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0013\n",
      "Epoch 53/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0013\n",
      "Epoch 54/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0012\n",
      "Epoch 55/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0012\n",
      "Epoch 56/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0012\n",
      "Epoch 57/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0012\n",
      "Epoch 58/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0012\n",
      "Epoch 59/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0012\n",
      "Epoch 60/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0011\n",
      "Epoch 61/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0011\n",
      "Epoch 62/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0011\n",
      "Epoch 63/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0011\n",
      "Epoch 64/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0011\n",
      "Epoch 65/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0011\n",
      "Epoch 66/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0010\n",
      "Epoch 67/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0010\n",
      "Epoch 68/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0010\n",
      "Epoch 69/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0010\n",
      "Epoch 70/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 9.8952e-04\n",
      "Epoch 71/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 9.7536e-04\n",
      "Epoch 72/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 9.6140e-04\n",
      "Epoch 73/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 9.4763e-04\n",
      "Epoch 74/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 9.3407e-04\n",
      "Epoch 75/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 9.2070e-04\n",
      "Epoch 76/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 9.0752e-04\n",
      "Epoch 77/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 8.9454e-04\n",
      "Epoch 78/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 8.8173e-04\n",
      "Epoch 79/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 8.6911e-04\n",
      "Epoch 80/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 8.5667e-04\n",
      "Epoch 81/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 8.4441e-04\n",
      "Epoch 82/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 8.3232e-04\n",
      "Epoch 83/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 8.2041e-04\n",
      "Epoch 84/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 8.0867e-04\n",
      "Epoch 85/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 7.9709e-04\n",
      "Epoch 86/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 7.8569e-04\n",
      "Epoch 87/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 7.7444e-04\n",
      "Epoch 88/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 7.6335e-04\n",
      "Epoch 89/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 7.5243e-04\n",
      "Epoch 90/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 7.4166e-04\n",
      "Epoch 91/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.3105e-04\n",
      "Epoch 92/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.2058e-04\n",
      "Epoch 93/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 7.1027e-04\n",
      "Epoch 94/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 7.0010e-04\n",
      "Epoch 95/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.9008e-04\n",
      "Epoch 96/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.8020e-04\n",
      "Epoch 97/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.7047e-04\n",
      "Epoch 98/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.6087e-04\n",
      "Epoch 99/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.5141e-04\n",
      "Epoch 100/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 6.4209e-04\n",
      "Epoch 101/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.3290e-04\n",
      "Epoch 102/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.2384e-04\n",
      "Epoch 103/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 6.1491e-04\n",
      "Epoch 104/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.0611e-04\n",
      "Epoch 105/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 5.9743e-04\n",
      "Epoch 106/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 5.8888e-04\n",
      "Epoch 107/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 5.8045e-04\n",
      "Epoch 108/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 5.7215e-04\n",
      "Epoch 109/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 5.6396e-04\n",
      "Epoch 110/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 5.5589e-04\n",
      "Epoch 111/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 5.4793e-04\n",
      "Epoch 112/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 5.4008e-04\n",
      "Epoch 113/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 5.3235e-04\n",
      "Epoch 114/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 5.2474e-04\n",
      "Epoch 115/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 5.1723e-04\n",
      "Epoch 116/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 5.0982e-04\n",
      "Epoch 117/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 5.0252e-04\n",
      "Epoch 118/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 4.9533e-04\n",
      "Epoch 119/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.8824e-04\n",
      "Epoch 120/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 4.8126e-04\n",
      "Epoch 121/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.7437e-04\n",
      "Epoch 122/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.6758e-04\n",
      "Epoch 123/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 4.6088e-04\n",
      "Epoch 124/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 4.5429e-04\n",
      "Epoch 125/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.4778e-04\n",
      "Epoch 126/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.4138e-04\n",
      "Epoch 127/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.3506e-04\n",
      "Epoch 128/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 4.2883e-04\n",
      "Epoch 129/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.2269e-04\n",
      "Epoch 130/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.1664e-04\n",
      "Epoch 131/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.1068e-04\n",
      "Epoch 132/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 4.0480e-04\n",
      "Epoch 133/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.9901e-04\n",
      "Epoch 134/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.9330e-04\n",
      "Epoch 135/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.8767e-04\n",
      "Epoch 136/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 3.8212e-04\n",
      "Epoch 137/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.7665e-04\n",
      "Epoch 138/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.7126e-04\n",
      "Epoch 139/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.6595e-04\n",
      "Epoch 140/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.6071e-04\n",
      "Epoch 141/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.5554e-04\n",
      "Epoch 142/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.5046e-04\n",
      "Epoch 143/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.4544e-04\n",
      "Epoch 144/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.4049e-04\n",
      "Epoch 145/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.3562e-04\n",
      "Epoch 146/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.3082e-04\n",
      "Epoch 147/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.2608e-04\n",
      "Epoch 148/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.2142e-04\n",
      "Epoch 149/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.1682e-04\n",
      "Epoch 150/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.1228e-04\n",
      "Epoch 151/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.0781e-04\n",
      "Epoch 152/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.0341e-04\n",
      "Epoch 153/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.9906e-04\n",
      "Epoch 154/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 2.9478e-04\n",
      "Epoch 155/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 2.9056e-04\n",
      "Epoch 156/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.8640e-04\n",
      "Epoch 157/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 2.8231e-04\n",
      "Epoch 158/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.7826e-04\n",
      "Epoch 159/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 2.7428e-04\n",
      "Epoch 160/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.7036e-04\n",
      "Epoch 161/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.6649e-04\n",
      "Epoch 162/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.6267e-04\n",
      "Epoch 163/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.5891e-04\n",
      "Epoch 164/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.5521e-04\n",
      "Epoch 165/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.5155e-04\n",
      "Epoch 166/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 2.4795e-04\n",
      "Epoch 167/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.4440e-04\n",
      "Epoch 168/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.4091e-04\n",
      "Epoch 169/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.3746e-04\n",
      "Epoch 170/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 2.3406e-04\n",
      "Epoch 171/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.3071e-04\n",
      "Epoch 172/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.2741e-04\n",
      "Epoch 173/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.2415e-04\n",
      "Epoch 174/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.2094e-04\n",
      "Epoch 175/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 2.1778e-04\n",
      "Epoch 176/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 2.1466e-04\n",
      "Epoch 177/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 2.1159e-04\n",
      "Epoch 178/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.0856e-04\n",
      "Epoch 179/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 2.0558e-04\n",
      "Epoch 180/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.0264e-04\n",
      "Epoch 181/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.9974e-04\n",
      "Epoch 182/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.9688e-04\n",
      "Epoch 183/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.9406e-04\n",
      "Epoch 184/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.9128e-04\n",
      "Epoch 185/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.8854e-04\n",
      "Epoch 186/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.8584e-04\n",
      "Epoch 187/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.8318e-04\n",
      "Epoch 188/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.8056e-04\n",
      "Epoch 189/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.7798e-04\n",
      "Epoch 190/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.7543e-04\n",
      "Epoch 191/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.7292e-04\n",
      "Epoch 192/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.7045e-04\n",
      "Epoch 193/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.6801e-04\n",
      "Epoch 194/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.6560e-04\n",
      "Epoch 195/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.6323e-04\n",
      "Epoch 196/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.6089e-04\n",
      "Epoch 197/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.5859e-04\n",
      "Epoch 198/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.5632e-04\n",
      "Epoch 199/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.5408e-04\n",
      "Epoch 200/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.5188e-04\n",
      "Epoch 201/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.4970e-04\n",
      "Epoch 202/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.4756e-04\n",
      "Epoch 203/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.4545e-04\n",
      "Epoch 204/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.4337e-04\n",
      "Epoch 205/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.4132e-04\n",
      "Epoch 206/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.3929e-04\n",
      "Epoch 207/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.3730e-04\n",
      "Epoch 208/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.3533e-04\n",
      "Epoch 209/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.3340e-04\n",
      "Epoch 210/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.3149e-04\n",
      "Epoch 211/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 1.2961e-04\n",
      "Epoch 212/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.2775e-04\n",
      "Epoch 213/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.2592e-04\n",
      "Epoch 214/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.2412e-04\n",
      "Epoch 215/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.2234e-04\n",
      "Epoch 216/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.2059e-04\n",
      "Epoch 217/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.1887e-04\n",
      "Epoch 218/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.1717e-04\n",
      "Epoch 219/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.1549e-04\n",
      "Epoch 220/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.1384e-04\n",
      "Epoch 221/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.1221e-04\n",
      "Epoch 222/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.1060e-04\n",
      "Epoch 223/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.0902e-04\n",
      "Epoch 224/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.0746e-04\n",
      "Epoch 225/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.0592e-04\n",
      "Epoch 226/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.0440e-04\n",
      "Epoch 227/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.0291e-04\n",
      "Epoch 228/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.0144e-04\n",
      "Epoch 229/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 9.9983e-05\n",
      "Epoch 230/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 9.8553e-05\n",
      "Epoch 231/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 9.7142e-05\n",
      "Epoch 232/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 9.5752e-05\n",
      "Epoch 233/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 9.4381e-05\n",
      "Epoch 234/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 9.3031e-05\n",
      "Epoch 235/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 9.1699e-05\n",
      "Epoch 236/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 9.0386e-05\n",
      "Epoch 237/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 8.9093e-05\n",
      "Epoch 238/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 8.7817e-05\n",
      "Epoch 239/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 8.6560e-05\n",
      "Epoch 240/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 8.5321e-05\n",
      "Epoch 241/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 8.4100e-05\n",
      "Epoch 242/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 8.2897e-05\n",
      "Epoch 243/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 8.1709e-05\n",
      "Epoch 244/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 8.0540e-05\n",
      "Epoch 245/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.9388e-05\n",
      "Epoch 246/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 7.8252e-05\n",
      "Epoch 247/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.7130e-05\n",
      "Epoch 248/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.6027e-05\n",
      "Epoch 249/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.4940e-05\n",
      "Epoch 250/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 7.3866e-05\n",
      "Epoch 251/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.2810e-05\n",
      "Epoch 252/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 7.1767e-05\n",
      "Epoch 253/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 7.0739e-05\n",
      "Epoch 254/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.9728e-05\n",
      "Epoch 255/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.8730e-05\n",
      "Epoch 256/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 6.7745e-05\n",
      "Epoch 257/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 6.6776e-05\n",
      "Epoch 258/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.5820e-05\n",
      "Epoch 259/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 6.4878e-05\n",
      "Epoch 260/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.3950e-05\n",
      "Epoch 261/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3034e-05\n",
      "Epoch 262/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.2132e-05\n",
      "Epoch 263/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.1243e-05\n",
      "Epoch 264/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 6.0366e-05\n",
      "Epoch 265/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 5.9502e-05\n",
      "Epoch 266/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 5.8651e-05\n",
      "Epoch 267/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 5.7811e-05\n",
      "Epoch 268/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 5.6984e-05\n",
      "Epoch 269/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 5.6168e-05\n",
      "Epoch 270/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 5.5364e-05\n",
      "Epoch 271/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 5.4572e-05\n",
      "Epoch 272/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 5.3791e-05\n",
      "Epoch 273/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 5.3020e-05\n",
      "Epoch 274/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 5.2261e-05\n",
      "Epoch 275/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 5.1514e-05\n",
      "Epoch 276/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 5.0777e-05\n",
      "Epoch 277/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 5.0050e-05\n",
      "Epoch 278/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 4.9334e-05\n",
      "Epoch 279/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 4.8627e-05\n",
      "Epoch 280/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 4.7931e-05\n",
      "Epoch 281/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 4.7245e-05\n",
      "Epoch 282/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 4.6569e-05\n",
      "Epoch 283/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 4.5902e-05\n",
      "Epoch 284/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 4.5245e-05\n",
      "Epoch 285/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 4.4598e-05\n",
      "Epoch 286/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 4.3959e-05\n",
      "Epoch 287/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 4.3330e-05\n",
      "Epoch 288/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 4.2710e-05\n",
      "Epoch 289/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 4.2099e-05\n",
      "Epoch 290/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 4.1496e-05\n",
      "Epoch 291/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 4.0902e-05\n",
      "Epoch 292/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 4.0317e-05\n",
      "Epoch 293/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 3.9740e-05\n",
      "Epoch 294/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.9171e-05\n",
      "Epoch 295/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.8610e-05\n",
      "Epoch 296/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 3.8058e-05\n",
      "Epoch 297/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.7513e-05\n",
      "Epoch 298/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 3.6976e-05\n",
      "Epoch 299/1000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.6447e-05\n",
      "Epoch 300/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.5926e-05\n",
      "Epoch 301/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 3.5411e-05\n",
      "Epoch 302/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.4904e-05\n",
      "Epoch 303/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.4405e-05\n",
      "Epoch 304/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 3.3913e-05\n",
      "Epoch 305/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 3.3427e-05\n",
      "Epoch 306/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.2948e-05\n",
      "Epoch 307/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.2477e-05\n",
      "Epoch 308/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 3.2012e-05\n",
      "Epoch 309/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 3.1554e-05\n",
      "Epoch 310/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 3.1103e-05\n",
      "Epoch 311/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 3.0657e-05\n",
      "Epoch 312/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.0218e-05\n",
      "Epoch 313/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 2.9786e-05\n",
      "Epoch 314/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 2.9359e-05\n",
      "Epoch 315/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 2.8939e-05\n",
      "Epoch 316/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 2.8525e-05\n",
      "Epoch 317/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 2.8116e-05\n",
      "Epoch 318/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 2.7714e-05\n",
      "Epoch 319/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 2.7318e-05\n",
      "Epoch 320/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 2.6926e-05\n",
      "Epoch 321/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 2.6541e-05\n",
      "Epoch 322/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 2.6162e-05\n",
      "Epoch 323/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 2.5787e-05\n",
      "Epoch 324/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 2.5418e-05\n",
      "Epoch 325/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 2.5054e-05\n",
      "Epoch 326/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 2.4695e-05\n",
      "Epoch 327/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 2.4342e-05\n",
      "Epoch 328/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 2.3993e-05\n",
      "Epoch 329/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 2.3650e-05\n",
      "Epoch 330/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 2.3312e-05\n",
      "Epoch 331/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 2.2978e-05\n",
      "Epoch 332/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 2.2649e-05\n",
      "Epoch 333/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 2.2325e-05\n",
      "Epoch 334/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 2.2005e-05\n",
      "Epoch 335/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 2.1690e-05\n",
      "Epoch 336/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 2.1380e-05\n",
      "Epoch 337/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 2.1074e-05\n",
      "Epoch 338/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 2.0772e-05\n",
      "Epoch 339/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 2.0475e-05\n",
      "Epoch 340/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 2.0182e-05\n",
      "Epoch 341/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.9893e-05\n",
      "Epoch 342/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.9609e-05\n",
      "Epoch 343/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.9328e-05\n",
      "Epoch 344/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 1.9051e-05\n",
      "Epoch 345/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.8778e-05\n",
      "Epoch 346/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.8510e-05\n",
      "Epoch 347/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.8245e-05\n",
      "Epoch 348/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.7983e-05\n",
      "Epoch 349/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.7726e-05\n",
      "Epoch 350/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 1.7472e-05\n",
      "Epoch 351/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.7222e-05\n",
      "Epoch 352/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.6976e-05\n",
      "Epoch 353/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.6733e-05\n",
      "Epoch 354/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.6493e-05\n",
      "Epoch 355/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.6257e-05\n",
      "Epoch 356/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 1.6024e-05\n",
      "Epoch 357/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 1.5795e-05\n",
      "Epoch 358/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.5569e-05\n",
      "Epoch 359/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 1.5346e-05\n",
      "Epoch 360/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.5127e-05\n",
      "Epoch 361/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 1.4910e-05\n",
      "Epoch 362/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.4697e-05\n",
      "Epoch 363/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.4487e-05\n",
      "Epoch 364/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.4279e-05\n",
      "Epoch 365/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.4075e-05\n",
      "Epoch 366/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.3873e-05\n",
      "Epoch 367/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.3674e-05\n",
      "Epoch 368/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 1.3479e-05\n",
      "Epoch 369/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.3286e-05\n",
      "Epoch 370/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.3096e-05\n",
      "Epoch 371/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.2908e-05\n",
      "Epoch 372/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 1.2724e-05\n",
      "Epoch 373/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.2541e-05\n",
      "Epoch 374/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.2362e-05\n",
      "Epoch 375/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.2185e-05\n",
      "Epoch 376/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 1.2011e-05\n",
      "Epoch 377/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 1.1839e-05\n",
      "Epoch 378/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.1669e-05\n",
      "Epoch 379/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1502e-05\n",
      "Epoch 380/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 1.1337e-05\n",
      "Epoch 381/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 1.1176e-05\n",
      "Epoch 382/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.1016e-05\n",
      "Epoch 383/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.0858e-05\n",
      "Epoch 384/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.0702e-05\n",
      "Epoch 385/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.0549e-05\n",
      "Epoch 386/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.0398e-05\n",
      "Epoch 387/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.0249e-05\n",
      "Epoch 388/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.0102e-05\n",
      "Epoch 389/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 9.9580e-06\n",
      "Epoch 390/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 9.8157e-06\n",
      "Epoch 391/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 9.6749e-06\n",
      "Epoch 392/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 9.5364e-06\n",
      "Epoch 393/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 9.3998e-06\n",
      "Epoch 394/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 9.2654e-06\n",
      "Epoch 395/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 9.1328e-06\n",
      "Epoch 396/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 9.0024e-06\n",
      "Epoch 397/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 8.8734e-06\n",
      "Epoch 398/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 8.7462e-06\n",
      "Epoch 399/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 8.6214e-06\n",
      "Epoch 400/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 8.4976e-06\n",
      "Epoch 401/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 8.3761e-06\n",
      "Epoch 402/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 8.2559e-06\n",
      "Epoch 403/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 8.1380e-06\n",
      "Epoch 404/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 8.0216e-06\n",
      "Epoch 405/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 7.9069e-06\n",
      "Epoch 406/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 7.7936e-06\n",
      "Epoch 407/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 7.6821e-06\n",
      "Epoch 408/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 7.5719e-06\n",
      "Epoch 409/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 7.4636e-06\n",
      "Epoch 410/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 7.3568e-06\n",
      "Epoch 411/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 7.2518e-06\n",
      "Epoch 412/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 7.1479e-06\n",
      "Epoch 413/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 7.0454e-06\n",
      "Epoch 414/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 6.9447e-06\n",
      "Epoch 415/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 6.8451e-06\n",
      "Epoch 416/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 6.7472e-06\n",
      "Epoch 417/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 6.6507e-06\n",
      "Epoch 418/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 6.5554e-06\n",
      "Epoch 419/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 6.4619e-06\n",
      "Epoch 420/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 6.3690e-06\n",
      "Epoch 421/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 6.2780e-06\n",
      "Epoch 422/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 6.1883e-06\n",
      "Epoch 423/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 6.0996e-06\n",
      "Epoch 424/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 6.0124e-06\n",
      "Epoch 425/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 5.9263e-06\n",
      "Epoch 426/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 5.8417e-06\n",
      "Epoch 427/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 5.7578e-06\n",
      "Epoch 428/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 5.6753e-06\n",
      "Epoch 429/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 5.5943e-06\n",
      "Epoch 430/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 5.5141e-06\n",
      "Epoch 431/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 5.4351e-06\n",
      "Epoch 432/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 5.3575e-06\n",
      "Epoch 433/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 5.2808e-06\n",
      "Epoch 434/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 5.2052e-06\n",
      "Epoch 435/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 5.1306e-06\n",
      "Epoch 436/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 5.0571e-06\n",
      "Epoch 437/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 4.9848e-06\n",
      "Epoch 438/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 4.9136e-06\n",
      "Epoch 439/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 4.8432e-06\n",
      "Epoch 440/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 4.7738e-06\n",
      "Epoch 441/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 4.7056e-06\n",
      "Epoch 442/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 4.6382e-06\n",
      "Epoch 443/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 4.5719e-06\n",
      "Epoch 444/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 4.5062e-06\n",
      "Epoch 445/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 4.4419e-06\n",
      "Epoch 446/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 4.3783e-06\n",
      "Epoch 447/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 4.3155e-06\n",
      "Epoch 448/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 4.2537e-06\n",
      "Epoch 449/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 4.1931e-06\n",
      "Epoch 450/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 4.1329e-06\n",
      "Epoch 451/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 4.0738e-06\n",
      "Epoch 452/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 4.0153e-06\n",
      "Epoch 453/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 3.9578e-06\n",
      "Epoch 454/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 3.9012e-06\n",
      "Epoch 455/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.8456e-06\n",
      "Epoch 456/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.7905e-06\n",
      "Epoch 457/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 3.7364e-06\n",
      "Epoch 458/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 3.6827e-06\n",
      "Epoch 459/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 3.6300e-06\n",
      "Epoch 460/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 3.5780e-06\n",
      "Epoch 461/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 3.5269e-06\n",
      "Epoch 462/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 3.4764e-06\n",
      "Epoch 463/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.4266e-06\n",
      "Epoch 464/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 3.3776e-06\n",
      "Epoch 465/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.3292e-06\n",
      "Epoch 466/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 3.2815e-06\n",
      "Epoch 467/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 3.2345e-06\n",
      "Epoch 468/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.1882e-06\n",
      "Epoch 469/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.1426e-06\n",
      "Epoch 470/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 3.0976e-06\n",
      "Epoch 471/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.0532e-06\n",
      "Epoch 472/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.0096e-06\n",
      "Epoch 473/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 2.9665e-06\n",
      "Epoch 474/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 2.9242e-06\n",
      "Epoch 475/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 2.8822e-06\n",
      "Epoch 476/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 2.8410e-06\n",
      "Epoch 477/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 2.8003e-06\n",
      "Epoch 478/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 2.7602e-06\n",
      "Epoch 479/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 2.7208e-06\n",
      "Epoch 480/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 2.6819e-06\n",
      "Epoch 481/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 2.6435e-06\n",
      "Epoch 482/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 2.6057e-06\n",
      "Epoch 483/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 2.5682e-06\n",
      "Epoch 484/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 2.5316e-06\n",
      "Epoch 485/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 2.4954e-06\n",
      "Epoch 486/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 2.4595e-06\n",
      "Epoch 487/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 2.4245e-06\n",
      "Epoch 488/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 2.3897e-06\n",
      "Epoch 489/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 2.3555e-06\n",
      "Epoch 490/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 2.3218e-06\n",
      "Epoch 491/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 2.2885e-06\n",
      "Epoch 492/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 2.2559e-06\n",
      "Epoch 493/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 2.2234e-06\n",
      "Epoch 494/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 2.1916e-06\n",
      "Epoch 495/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 2.1604e-06\n",
      "Epoch 496/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 2.1294e-06\n",
      "Epoch 497/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 2.0989e-06\n",
      "Epoch 498/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 2.0689e-06\n",
      "Epoch 499/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 2.0392e-06\n",
      "Epoch 500/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 2.0100e-06\n",
      "Epoch 501/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 1.9813e-06\n",
      "Epoch 502/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.9529e-06\n",
      "Epoch 503/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.9250e-06\n",
      "Epoch 504/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 1.8975e-06\n",
      "Epoch 505/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.8703e-06\n",
      "Epoch 506/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.8435e-06\n",
      "Epoch 507/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.8171e-06\n",
      "Epoch 508/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.7911e-06\n",
      "Epoch 509/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.7655e-06\n",
      "Epoch 510/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.7402e-06\n",
      "Epoch 511/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.7153e-06\n",
      "Epoch 512/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.6908e-06\n",
      "Epoch 513/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 1.6665e-06\n",
      "Epoch 514/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.6427e-06\n",
      "Epoch 515/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 1.6191e-06\n",
      "Epoch 516/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 1.5960e-06\n",
      "Epoch 517/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 1.5731e-06\n",
      "Epoch 518/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 1.5507e-06\n",
      "Epoch 519/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 1.5285e-06\n",
      "Epoch 520/1000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 1.5065e-06\n",
      "Epoch 521/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 1.4849e-06\n",
      "Epoch 522/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.4638e-06\n",
      "Epoch 523/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 1.4428e-06\n",
      "Epoch 524/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.4221e-06\n",
      "Epoch 525/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 1.4018e-06\n",
      "Epoch 526/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 1.3818e-06\n",
      "Epoch 527/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 1.3619e-06\n",
      "Epoch 528/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.3424e-06\n",
      "Epoch 529/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.3232e-06\n",
      "Epoch 530/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.3042e-06\n",
      "Epoch 531/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.2856e-06\n",
      "Epoch 532/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 1.2672e-06\n",
      "Epoch 533/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.2491e-06\n",
      "Epoch 534/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.2312e-06\n",
      "Epoch 535/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 1.2135e-06\n",
      "Epoch 536/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 1.1962e-06\n",
      "Epoch 537/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1.1791e-06\n",
      "Epoch 538/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 1.1622e-06\n",
      "Epoch 539/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.1455e-06\n",
      "Epoch 540/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.1292e-06\n",
      "Epoch 541/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.1130e-06\n",
      "Epoch 542/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.0971e-06\n",
      "Epoch 543/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0814e-06\n",
      "Epoch 544/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.0659e-06\n",
      "Epoch 545/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.0506e-06\n",
      "Epoch 546/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.0357e-06\n",
      "Epoch 547/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.0208e-06\n",
      "Epoch 548/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.0062e-06\n",
      "Epoch 549/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 9.9183e-07\n",
      "Epoch 550/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 9.7760e-07\n",
      "Epoch 551/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 9.6355e-07\n",
      "Epoch 552/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 9.4978e-07\n",
      "Epoch 553/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 9.3615e-07\n",
      "Epoch 554/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 9.2281e-07\n",
      "Epoch 555/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 9.0965e-07\n",
      "Epoch 556/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 8.9663e-07\n",
      "Epoch 557/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 8.8372e-07\n",
      "Epoch 558/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 8.7112e-07\n",
      "Epoch 559/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 8.5860e-07\n",
      "Epoch 560/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 8.4632e-07\n",
      "Epoch 561/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 8.3419e-07\n",
      "Epoch 562/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 8.2222e-07\n",
      "Epoch 563/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 8.1047e-07\n",
      "Epoch 564/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 7.9883e-07\n",
      "Epoch 565/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 7.8747e-07\n",
      "Epoch 566/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 7.7618e-07\n",
      "Epoch 567/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 7.6506e-07\n",
      "Epoch 568/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 7.5412e-07\n",
      "Epoch 569/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 7.4334e-07\n",
      "Epoch 570/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.3269e-07\n",
      "Epoch 571/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.2225e-07\n",
      "Epoch 572/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 7.1190e-07\n",
      "Epoch 573/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.0171e-07\n",
      "Epoch 574/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 6.9167e-07\n",
      "Epoch 575/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 6.8178e-07\n",
      "Epoch 576/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.7200e-07\n",
      "Epoch 577/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.6232e-07\n",
      "Epoch 578/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 6.5294e-07\n",
      "Epoch 579/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 6.4357e-07\n",
      "Epoch 580/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3439e-07\n",
      "Epoch 581/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.2533e-07\n",
      "Epoch 582/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.1631e-07\n",
      "Epoch 583/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.0747e-07\n",
      "Epoch 584/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 5.9884e-07\n",
      "Epoch 585/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 5.9026e-07\n",
      "Epoch 586/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 5.8176e-07\n",
      "Epoch 587/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 5.7342e-07\n",
      "Epoch 588/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 5.6524e-07\n",
      "Epoch 589/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 5.5710e-07\n",
      "Epoch 590/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 5.4918e-07\n",
      "Epoch 591/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 5.4131e-07\n",
      "Epoch 592/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 5.3357e-07\n",
      "Epoch 593/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 5.2592e-07\n",
      "Epoch 594/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 5.1844e-07\n",
      "Epoch 595/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 5.1095e-07\n",
      "Epoch 596/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 5.0368e-07\n",
      "Epoch 597/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.9644e-07\n",
      "Epoch 598/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 4.8937e-07\n",
      "Epoch 599/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 4.8236e-07\n",
      "Epoch 600/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.7548e-07\n",
      "Epoch 601/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 4.6870e-07\n",
      "Epoch 602/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 4.6192e-07\n",
      "Epoch 603/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 4.5535e-07\n",
      "Epoch 604/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.4880e-07\n",
      "Epoch 605/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 4.4242e-07\n",
      "Epoch 606/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 4.3602e-07\n",
      "Epoch 607/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.2985e-07\n",
      "Epoch 608/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 4.2363e-07\n",
      "Epoch 609/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.1760e-07\n",
      "Epoch 610/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.1162e-07\n",
      "Epoch 611/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 4.0572e-07\n",
      "Epoch 612/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.9992e-07\n",
      "Epoch 613/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.9420e-07\n",
      "Epoch 614/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.8856e-07\n",
      "Epoch 615/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.8301e-07\n",
      "Epoch 616/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.7747e-07\n",
      "Epoch 617/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.7214e-07\n",
      "Epoch 618/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.6675e-07\n",
      "Epoch 619/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.6149e-07\n",
      "Epoch 620/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.5635e-07\n",
      "Epoch 621/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.5123e-07\n",
      "Epoch 622/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.4625e-07\n",
      "Epoch 623/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.4128e-07\n",
      "Epoch 624/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.3636e-07\n",
      "Epoch 625/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.3157e-07\n",
      "Epoch 626/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.2684e-07\n",
      "Epoch 627/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.2217e-07\n",
      "Epoch 628/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.1754e-07\n",
      "Epoch 629/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.1302e-07\n",
      "Epoch 630/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.0852e-07\n",
      "Epoch 631/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.0411e-07\n",
      "Epoch 632/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 2.9973e-07\n",
      "Epoch 633/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.9546e-07\n",
      "Epoch 634/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.9124e-07\n",
      "Epoch 635/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.8703e-07\n",
      "Epoch 636/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 2.8294e-07\n",
      "Epoch 637/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.7886e-07\n",
      "Epoch 638/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.7486e-07\n",
      "Epoch 639/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 2.7102e-07\n",
      "Epoch 640/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.6711e-07\n",
      "Epoch 641/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.6330e-07\n",
      "Epoch 642/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.5948e-07\n",
      "Epoch 643/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.5578e-07\n",
      "Epoch 644/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.5217e-07\n",
      "Epoch 645/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 2.4854e-07\n",
      "Epoch 646/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.4500e-07\n",
      "Epoch 647/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.4144e-07\n",
      "Epoch 648/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 2.3799e-07\n",
      "Epoch 649/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.3461e-07\n",
      "Epoch 650/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.3125e-07\n",
      "Epoch 651/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 2.2795e-07\n",
      "Epoch 652/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 2.2468e-07\n",
      "Epoch 653/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.2145e-07\n",
      "Epoch 654/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.1825e-07\n",
      "Epoch 655/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.1513e-07\n",
      "Epoch 656/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 2.1208e-07\n",
      "Epoch 657/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.0906e-07\n",
      "Epoch 658/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.0604e-07\n",
      "Epoch 659/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.0313e-07\n",
      "Epoch 660/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 2.0016e-07\n",
      "Epoch 661/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.9737e-07\n",
      "Epoch 662/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.9453e-07\n",
      "Epoch 663/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.9176e-07\n",
      "Epoch 664/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.8896e-07\n",
      "Epoch 665/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.8631e-07\n",
      "Epoch 666/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.8357e-07\n",
      "Epoch 667/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.8096e-07\n",
      "Epoch 668/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.7838e-07\n",
      "Epoch 669/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.7582e-07\n",
      "Epoch 670/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.7332e-07\n",
      "Epoch 671/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.7084e-07\n",
      "Epoch 672/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.6842e-07\n",
      "Epoch 673/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.6598e-07\n",
      "Epoch 674/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.6361e-07\n",
      "Epoch 675/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.6126e-07\n",
      "Epoch 676/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.5898e-07\n",
      "Epoch 677/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.5670e-07\n",
      "Epoch 678/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.5445e-07\n",
      "Epoch 679/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.5222e-07\n",
      "Epoch 680/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.5005e-07\n",
      "Epoch 681/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.4789e-07\n",
      "Epoch 682/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.4579e-07\n",
      "Epoch 683/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.4371e-07\n",
      "Epoch 684/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.4165e-07\n",
      "Epoch 685/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.3965e-07\n",
      "Epoch 686/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.3760e-07\n",
      "Epoch 687/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.3564e-07\n",
      "Epoch 688/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.3370e-07\n",
      "Epoch 689/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.3183e-07\n",
      "Epoch 690/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.2993e-07\n",
      "Epoch 691/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.2804e-07\n",
      "Epoch 692/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.2621e-07\n",
      "Epoch 693/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.2443e-07\n",
      "Epoch 694/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.2263e-07\n",
      "Epoch 695/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.2088e-07\n",
      "Epoch 696/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.1914e-07\n",
      "Epoch 697/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.1741e-07\n",
      "Epoch 698/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.1576e-07\n",
      "Epoch 699/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1413e-07\n",
      "Epoch 700/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.1249e-07\n",
      "Epoch 701/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1083e-07\n",
      "Epoch 702/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.0929e-07\n",
      "Epoch 703/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.0772e-07\n",
      "Epoch 704/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.0615e-07\n",
      "Epoch 705/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.0463e-07\n",
      "Epoch 706/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.0317e-07\n",
      "Epoch 707/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.0170e-07\n",
      "Epoch 708/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.0022e-07\n",
      "Epoch 709/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 9.8767e-08\n",
      "Epoch 710/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 9.7380e-08\n",
      "Epoch 711/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 9.5982e-08\n",
      "Epoch 712/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 9.4597e-08\n",
      "Epoch 713/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 9.3273e-08\n",
      "Epoch 714/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 9.1918e-08\n",
      "Epoch 715/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 9.0602e-08\n",
      "Epoch 716/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 8.9285e-08\n",
      "Epoch 717/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 8.8043e-08\n",
      "Epoch 718/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 8.6746e-08\n",
      "Epoch 719/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 8.5536e-08\n",
      "Epoch 720/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 8.4304e-08\n",
      "Epoch 721/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 8.3083e-08\n",
      "Epoch 722/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 8.1895e-08\n",
      "Epoch 723/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 8.0721e-08\n",
      "Epoch 724/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 7.9576e-08\n",
      "Epoch 725/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.8457e-08\n",
      "Epoch 726/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 7.7312e-08\n",
      "Epoch 727/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 7.6214e-08\n",
      "Epoch 728/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.5125e-08\n",
      "Epoch 729/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 7.4043e-08\n",
      "Epoch 730/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.2986e-08\n",
      "Epoch 731/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 7.1915e-08\n",
      "Epoch 732/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 7.0909e-08\n",
      "Epoch 733/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.9913e-08\n",
      "Epoch 734/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.8871e-08\n",
      "Epoch 735/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 6.7915e-08\n",
      "Epoch 736/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 6.6911e-08\n",
      "Epoch 737/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.5977e-08\n",
      "Epoch 738/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.5031e-08\n",
      "Epoch 739/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 6.4112e-08\n",
      "Epoch 740/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.3195e-08\n",
      "Epoch 741/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 6.2271e-08\n",
      "Epoch 742/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.1384e-08\n",
      "Epoch 743/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.0508e-08\n",
      "Epoch 744/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 5.9645e-08\n",
      "Epoch 745/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 5.8785e-08\n",
      "Epoch 746/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 5.7947e-08\n",
      "Epoch 747/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 5.7126e-08\n",
      "Epoch 748/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 5.6293e-08\n",
      "Epoch 749/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 5.5482e-08\n",
      "Epoch 750/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 5.4703e-08\n",
      "Epoch 751/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 5.3929e-08\n",
      "Epoch 752/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 5.3123e-08\n",
      "Epoch 753/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 5.2367e-08\n",
      "Epoch 754/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 5.1622e-08\n",
      "Epoch 755/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 5.0909e-08\n",
      "Epoch 756/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 5.0155e-08\n",
      "Epoch 757/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 4.9458e-08\n",
      "Epoch 758/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 4.8722e-08\n",
      "Epoch 759/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 4.8052e-08\n",
      "Epoch 760/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.7335e-08\n",
      "Epoch 761/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 4.6664e-08\n",
      "Epoch 762/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 4.5998e-08\n",
      "Epoch 763/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 4.5361e-08\n",
      "Epoch 764/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 4.4697e-08\n",
      "Epoch 765/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.4046e-08\n",
      "Epoch 766/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 4.3438e-08\n",
      "Epoch 767/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 4.2824e-08\n",
      "Epoch 768/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.2197e-08\n",
      "Epoch 769/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 4.1576e-08\n",
      "Epoch 770/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.1000e-08\n",
      "Epoch 771/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 4.0401e-08\n",
      "Epoch 772/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.9837e-08\n",
      "Epoch 773/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.9251e-08\n",
      "Epoch 774/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.8706e-08\n",
      "Epoch 775/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.8141e-08\n",
      "Epoch 776/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.7610e-08\n",
      "Epoch 777/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 3.7060e-08\n",
      "Epoch 778/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.6531e-08\n",
      "Epoch 779/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.6021e-08\n",
      "Epoch 780/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.5485e-08\n",
      "Epoch 781/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.4994e-08\n",
      "Epoch 782/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.4487e-08\n",
      "Epoch 783/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.3981e-08\n",
      "Epoch 784/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.3504e-08\n",
      "Epoch 785/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.3028e-08\n",
      "Epoch 786/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.2560e-08\n",
      "Epoch 787/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 3.2096e-08\n",
      "Epoch 788/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.1638e-08\n",
      "Epoch 789/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.1187e-08\n",
      "Epoch 790/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.0736e-08\n",
      "Epoch 791/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.0293e-08\n",
      "Epoch 792/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.9856e-08\n",
      "Epoch 793/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.9423e-08\n",
      "Epoch 794/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 2.9006e-08\n",
      "Epoch 795/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 2.8594e-08\n",
      "Epoch 796/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 2.8193e-08\n",
      "Epoch 797/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.7781e-08\n",
      "Epoch 798/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.7370e-08\n",
      "Epoch 799/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.6993e-08\n",
      "Epoch 800/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 2.6594e-08\n",
      "Epoch 801/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 2.6239e-08\n",
      "Epoch 802/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 2.5854e-08\n",
      "Epoch 803/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 2.5473e-08\n",
      "Epoch 804/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.5121e-08\n",
      "Epoch 805/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 2.4759e-08\n",
      "Epoch 806/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.4399e-08\n",
      "Epoch 807/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.4048e-08\n",
      "Epoch 808/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.3703e-08\n",
      "Epoch 809/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 2.3353e-08\n",
      "Epoch 810/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.3040e-08\n",
      "Epoch 811/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 2.2707e-08\n",
      "Epoch 812/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 2.2375e-08\n",
      "Epoch 813/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.2059e-08\n",
      "Epoch 814/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 2.1739e-08\n",
      "Epoch 815/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 2.1426e-08\n",
      "Epoch 816/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 2.1120e-08\n",
      "Epoch 817/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.0820e-08\n",
      "Epoch 818/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.0532e-08\n",
      "Epoch 819/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.0232e-08\n",
      "Epoch 820/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 1.9940e-08\n",
      "Epoch 821/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.9644e-08\n",
      "Epoch 822/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.9370e-08\n",
      "Epoch 823/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.9093e-08\n",
      "Epoch 824/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.8823e-08\n",
      "Epoch 825/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.8553e-08\n",
      "Epoch 826/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.8293e-08\n",
      "Epoch 827/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.8022e-08\n",
      "Epoch 828/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.7756e-08\n",
      "Epoch 829/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.7518e-08\n",
      "Epoch 830/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.7262e-08\n",
      "Epoch 831/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.7008e-08\n",
      "Epoch 832/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.6782e-08\n",
      "Epoch 833/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.6534e-08\n",
      "Epoch 834/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.6293e-08\n",
      "Epoch 835/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.6053e-08\n",
      "Epoch 836/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 1.5831e-08\n",
      "Epoch 837/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.5611e-08\n",
      "Epoch 838/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.5377e-08\n",
      "Epoch 839/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.5171e-08\n",
      "Epoch 840/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.4944e-08\n",
      "Epoch 841/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.4727e-08\n",
      "Epoch 842/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.4514e-08\n",
      "Epoch 843/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.4316e-08\n",
      "Epoch 844/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.4107e-08\n",
      "Epoch 845/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.3899e-08\n",
      "Epoch 846/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.3711e-08\n",
      "Epoch 847/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.3517e-08\n",
      "Epoch 848/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.3320e-08\n",
      "Epoch 849/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.3123e-08\n",
      "Epoch 850/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.2939e-08\n",
      "Epoch 851/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.2752e-08\n",
      "Epoch 852/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.2567e-08\n",
      "Epoch 853/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 1.2387e-08\n",
      "Epoch 854/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.2222e-08\n",
      "Epoch 855/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.2049e-08\n",
      "Epoch 856/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.1865e-08\n",
      "Epoch 857/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.1699e-08\n",
      "Epoch 858/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1536e-08\n",
      "Epoch 859/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1363e-08\n",
      "Epoch 860/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.1202e-08\n",
      "Epoch 861/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.1039e-08\n",
      "Epoch 862/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.0887e-08\n",
      "Epoch 863/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.0731e-08\n",
      "Epoch 864/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.0581e-08\n",
      "Epoch 865/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0416e-08\n",
      "Epoch 866/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.0270e-08\n",
      "Epoch 867/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.0128e-08\n",
      "Epoch 868/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 9.9843e-09\n",
      "Epoch 869/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 9.8366e-09\n",
      "Epoch 870/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 9.6962e-09\n",
      "Epoch 871/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 9.5599e-09\n",
      "Epoch 872/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 9.4280e-09\n",
      "Epoch 873/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 9.2874e-09\n",
      "Epoch 874/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 9.1599e-09\n",
      "Epoch 875/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 9.0185e-09\n",
      "Epoch 876/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 8.8898e-09\n",
      "Epoch 877/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 8.7725e-09\n",
      "Epoch 878/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 8.6403e-09\n",
      "Epoch 879/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 8.5139e-09\n",
      "Epoch 880/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 8.3970e-09\n",
      "Epoch 881/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 8.2791e-09\n",
      "Epoch 882/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 8.1597e-09\n",
      "Epoch 883/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 8.0375e-09\n",
      "Epoch 884/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.9262e-09\n",
      "Epoch 885/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.8088e-09\n",
      "Epoch 886/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 7.7055e-09\n",
      "Epoch 887/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 7.5887e-09\n",
      "Epoch 888/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.4856e-09\n",
      "Epoch 889/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 7.3721e-09\n",
      "Epoch 890/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.2673e-09\n",
      "Epoch 891/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.1675e-09\n",
      "Epoch 892/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.0657e-09\n",
      "Epoch 893/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.9596e-09\n",
      "Epoch 894/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.8607e-09\n",
      "Epoch 895/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 6.7591e-09\n",
      "Epoch 896/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.6598e-09\n",
      "Epoch 897/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 6.5694e-09\n",
      "Epoch 898/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.4731e-09\n",
      "Epoch 899/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 6.3803e-09\n",
      "Epoch 900/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 6.2966e-09\n",
      "Epoch 901/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.2031e-09\n",
      "Epoch 902/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.1140e-09\n",
      "Epoch 903/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 6.0238e-09\n",
      "Epoch 904/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 5.9395e-09\n",
      "Epoch 905/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 5.8548e-09\n",
      "Epoch 906/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 5.7662e-09\n",
      "Epoch 907/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 5.6864e-09\n",
      "Epoch 908/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 5.6101e-09\n",
      "Epoch 909/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 5.5292e-09\n",
      "Epoch 910/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 5.4494e-09\n",
      "Epoch 911/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 5.3719e-09\n",
      "Epoch 912/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 5.2874e-09\n",
      "Epoch 913/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 5.2125e-09\n",
      "Epoch 914/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 5.1461e-09\n",
      "Epoch 915/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 5.0709e-09\n",
      "Epoch 916/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.9998e-09\n",
      "Epoch 917/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 4.9213e-09\n",
      "Epoch 918/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 4.8503e-09\n",
      "Epoch 919/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 4.7812e-09\n",
      "Epoch 920/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 4.7141e-09\n",
      "Epoch 921/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 4.6483e-09\n",
      "Epoch 922/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.5865e-09\n",
      "Epoch 923/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 4.5174e-09\n",
      "Epoch 924/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.4493e-09\n",
      "Epoch 925/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 4.3863e-09\n",
      "Epoch 926/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 4.3300e-09\n",
      "Epoch 927/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 4.2634e-09\n",
      "Epoch 928/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 4.2067e-09\n",
      "Epoch 929/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.1439e-09\n",
      "Epoch 930/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.0823e-09\n",
      "Epoch 931/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 4.0239e-09\n",
      "Epoch 932/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 3.9614e-09\n",
      "Epoch 933/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.9078e-09\n",
      "Epoch 934/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.8596e-09\n",
      "Epoch 935/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.7982e-09\n",
      "Epoch 936/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.7456e-09\n",
      "Epoch 937/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.6890e-09\n",
      "Epoch 938/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 3.6397e-09\n",
      "Epoch 939/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.5829e-09\n",
      "Epoch 940/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.5345e-09\n",
      "Epoch 941/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.4855e-09\n",
      "Epoch 942/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 3.4378e-09\n",
      "Epoch 943/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.3849e-09\n",
      "Epoch 944/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.3380e-09\n",
      "Epoch 945/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.2896e-09\n",
      "Epoch 946/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.2433e-09\n",
      "Epoch 947/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.1925e-09\n",
      "Epoch 948/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.1450e-09\n",
      "Epoch 949/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.1091e-09\n",
      "Epoch 950/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.0612e-09\n",
      "Epoch 951/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.0200e-09\n",
      "Epoch 952/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.9733e-09\n",
      "Epoch 953/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.9309e-09\n",
      "Epoch 954/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 2.8881e-09\n",
      "Epoch 955/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.8453e-09\n",
      "Epoch 956/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.8084e-09\n",
      "Epoch 957/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 2.7701e-09\n",
      "Epoch 958/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.7290e-09\n",
      "Epoch 959/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 2.6881e-09\n",
      "Epoch 960/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.6525e-09\n",
      "Epoch 961/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.6114e-09\n",
      "Epoch 962/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 2.5724e-09\n",
      "Epoch 963/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.5334e-09\n",
      "Epoch 964/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.5003e-09\n",
      "Epoch 965/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.4674e-09\n",
      "Epoch 966/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.4310e-09\n",
      "Epoch 967/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.3946e-09\n",
      "Epoch 968/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 2.3639e-09\n",
      "Epoch 969/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.3288e-09\n",
      "Epoch 970/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.2937e-09\n",
      "Epoch 971/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.2585e-09\n",
      "Epoch 972/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 2.2244e-09\n",
      "Epoch 973/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.1953e-09\n",
      "Epoch 974/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.1678e-09\n",
      "Epoch 975/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 2.1353e-09\n",
      "Epoch 976/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.1038e-09\n",
      "Epoch 977/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 2.0745e-09\n",
      "Epoch 978/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.0421e-09\n",
      "Epoch 979/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.0171e-09\n",
      "Epoch 980/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.9864e-09\n",
      "Epoch 981/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.9569e-09\n",
      "Epoch 982/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 1.9274e-09\n",
      "Epoch 983/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.8999e-09\n",
      "Epoch 984/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.8722e-09\n",
      "Epoch 985/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.8484e-09\n",
      "Epoch 986/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.8223e-09\n",
      "Epoch 987/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.7942e-09\n",
      "Epoch 988/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 1.7674e-09\n",
      "Epoch 989/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.7414e-09\n",
      "Epoch 990/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.7207e-09\n",
      "Epoch 991/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.6949e-09\n",
      "Epoch 992/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.6710e-09\n",
      "Epoch 993/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.6462e-09\n",
      "Epoch 994/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.6264e-09\n",
      "Epoch 995/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.6026e-09\n",
      "Epoch 996/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.5798e-09\n",
      "Epoch 997/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 1.5568e-09\n",
      "Epoch 998/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.5335e-09\n",
      "Epoch 999/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.5113e-09\n",
      "Epoch 1000/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.4899e-09\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x28d7f69c7f0>"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train model with 1000 epochs\n",
    "model.fit(xs, ys, epochs=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[349997.59197235]]\n"
     ]
    }
   ],
   "source": [
    "# predict the price for 7-bedroom house price\n",
    "prediction = model.predict([7.0]) \n",
    "print(prediction*100000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise-2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise-2 has 20 points**.\n",
    "\n",
    "In this notebook you learned how to do classification using Fashion MNIST, a data set containing items of clothing, and a similar dataset called MNIST which has items of handwriting -- the digits 0 through 9.\n",
    "\n",
    "Write an MNIST classifier that trains to 99% accuracy or above, and does it without a fixed number of epochs -- i.e. you should stop training once you reach that level of accuracy using `callbacks`.\n",
    "\n",
    "- **Requirements**:\n",
    "1. It should succeed in less than 10 epochs.\n",
    "2. When it reaches 99% or greater it should print out the string `\"Reached 99% accuracy so cancelling training!\"` as specified in the `myCallback` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "class myCallback(tf.keras.callbacks.Callback):\n",
    "  def on_epoch_end(self, epoch, logs={}):\n",
    "    if(logs.get('accuracy')>0.99):\n",
    "      print(\"\\nReached 99% accuracy so cancelling training!\")\n",
    "      self.model.stop_training = True\n",
    "\n",
    "callbacks = myCallback()\n",
    "\n",
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "# load data\n",
    "(x_train, y_train),(x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# normalize data\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build model - be careful about the activation functions of the hidden layer and output layer\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dense(10, activation='softmax')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile model - be careful to use the correct loss for multi-class classification, metrics should be 'accuracy'\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2572 - accuracy: 0.9263\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1162 - accuracy: 0.9657\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0786 - accuracy: 0.9758\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0593 - accuracy: 0.9819\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0447 - accuracy: 0.9864\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0346 - accuracy: 0.9894\n",
      "Epoch 7/10\n",
      "1861/1875 [============================>.] - ETA: 0s - loss: 0.0275 - accuracy: 0.9913\n",
      "Reached 99% accuracy so cancelling training!\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0277 - accuracy: 0.9912\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x28cac32f220>"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train model with 10 epochs (will stop earlier) and callbacks\n",
    "# Note: Your output should include the message: \"Reached 99% accuracy so cancelling training!\"\n",
    "# The output should also include:\n",
    "# <tensorflow.python.keras.callbacks.History at MEMORY_ADDRESS> \n",
    "model.fit(x_train, y_train, epochs=10, callbacks=[callbacks])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [1] - [Tensorflow Website](https://www.tensorflow.org/)\n",
    "- [2] - [Tensorflow Tutorials](https://www.tensorflow.org/tutorials)\n",
    "- [3] - [Hands-On ML Textbook 2nd Edition](https://learning.oreilly.com/library/view/hands-on-machine-learning/9781492032632/)\n",
    "- [4] - [DeepLearning.AI TensorFlow Developer Professional Certificate - Course-1](https://www.coursera.org/professional-certificates/tensorflow-in-practice)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grading and Submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Name your notebook ```Lastname-tf-notebook.ipynb```. Submit the file using the ```tf-notebook``` link on Blackboard.\n",
    "\n",
    "- tf-notebook has a total of 30 points which will be counted towards the \"Assignment\" section of your final grade.\n",
    "\n",
    "- **RUN ALL CELLS REQUIREMENT**: You must run all cells to get the outputs and then attempt exercises. Otherwise, if any cell is not run with the correct output, your notebook gets ZERO even if you've completed the exercises.\n",
    "\n",
    "Grading will be based on \n",
    "\n",
    "  * verification of correct installation of Tensorflow\n",
    "  * error-free running of all the cells - all outputs and plots must be included - any missing output would cause the notebook to get ZERO!\n",
    "  * correct answers to the exercises - Exercise-1 [10 points], Exercise-2 [20 points]\n",
    "  \n",
    "<font color=red><b>Due Date: Tuesday April 19th, 11:59PM</b></font>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
